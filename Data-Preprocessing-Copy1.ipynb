{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!. ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "np.random.seed(1337)\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_args(*types):\n",
    "    def real_decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for val, typ in zip(args, types):\n",
    "                assert isinstance(val, typ), \"Value {} is not of expected type {}\".format(val, typ)\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return real_decorator\n",
    "\n",
    "def do_long_computation(name):\n",
    "    \"\"\" dummy function \"\"\"\n",
    "    time.sleep(10)\n",
    "    return \"FruitMart\"\n",
    "\n",
    "@check_args(str, int, int)\n",
    "def print_fruit(name, apples, oranges):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "evt_name = 'Featurespace_events_output.csv'\n",
    "auth_name = 'Featurespace_auths_output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir+evt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pure = pd.read_csv(data_dir+auth_name,nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pure.TSYS_DCLN_REAS_CD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Nuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARD_VFCN_REJ_CD has only NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('acct_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_lbl = df.groupby('FRD_IND')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped_lbl.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var=grouped_lbl.count().stack()\n",
    "temp=var.unstack()\n",
    "type(temp)\n",
    "x_list = temp['acct_id']\n",
    "label_list = temp.index\n",
    "plt.axis(\"equal\") #The pie chart is oval by default. To make it a circle use pyplot.axis(\"equal\")\n",
    "#To show the percentage of each pie slice, pass an output format to the autopctparameter \n",
    "plt.pie(x_list,labels=label_list,autopct=\"%1.1f%%\") \n",
    "plt.title(\"Transactions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c,col in enumerate(col_names):\n",
    "    var=grouped_lbl.count().stack()\n",
    "    temp=var.unstack()\n",
    "    type(temp)\n",
    "    x_list = temp[col]\n",
    "    label_list = temp.index\n",
    "    plt.axis(\"equal\") #The pie chart is oval by default. To make it a circle use pyplot.axis(\"equal\")\n",
    "    #To show the percentage of each pie slice, pass an output format to the autopctparameter\n",
    "#     plt.subplot(12,4,c+1)\n",
    "    plt.pie(x_list,labels=label_list,autopct=\"%1.1f%%\") \n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "    if c==45:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def value_exist(val,col,df):\n",
    "    keys = set(df.groupby(col).groups.keys())\n",
    "    print keys\n",
    "    return val in keys\n",
    "col = 'AUTHZN_APPRL_CD'\n",
    "value_exist(55555,col,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = 55555\n",
    "df_rmna = df.fillna(value={'AUTHZN_APPRL_CD':val})\n",
    "df_rmna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_auth = pd.read_csv(data_dir+auth_name,nrows=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_auth[df_auth['MRCH_CITY_NM'].isnull() & df_auth['MRCH_NM']=='FYP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_auth['MRCH_NM'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_auth.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import datetime as dt\n",
    "from IPython.display import display\n",
    "\n",
    "import plotly.plotly as py # interactive graphing\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import Bar, Scatter, Marker, Layout, Figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "evt_name = 'Featurespace_events_output.csv'\n",
    "auth_name = 'Featurespace_auths_output.csv'\n",
    "db_name = 'c1_agg.db'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disk_engine = create_engine('sqlite:///'+data_dir+db_name,convert_unicode=True)\n",
    "disk_engine.raw_connection().connection.text_factory = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = 'data_trim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query('select distinct FRD_IND,count(distinct acct_id) as num_usr '\n",
    "                       'from {table} '\n",
    "                       'group by FRD_IND'.format(table=table), disk_engine)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['num_usr'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = 'Fraud by Distinct Users'\n",
    "fig = {\n",
    "    'data': [{'labels': ['Fraud', 'Genuine'],\n",
    "              'values': [df['num_usr'][1], df['num_usr'][0]],\n",
    "              'type': 'pie'}],\n",
    "    'layout': {'title': title}\n",
    "     }\n",
    "iplot(fig,filename='figures/'+title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usr_ratio = df['num_usr'][0]/ df['num_usr'][1]\n",
    "usr_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usr_ratio= 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ds_u = pd.read_sql_query('select distinct acct_id, FRD_IND '\n",
    "                       'from {table} '\n",
    "                       'order by FRD_IND'.format(table=table), disk_engine)\n",
    "df_ds_u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_t_u = pd.read_sql_query('select acct_id, count(*) as num_trans '\n",
    "                       'from {table} '\n",
    "                        'group by acct_id '\n",
    "                        'order by -num_trans'.format(table=table), disk_engine)\n",
    "df_t_u "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total # Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trans = df_t_u['num_trans'] \n",
    "total_eg = 0\n",
    "for t_len in num_trans:\n",
    "    total_eg += math.ceil(t_len/50.0)\n",
    "print total_eg*0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "math.ceil(152/50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###graph bars %fraud al transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_val = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table= 'data_little'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_column(df_col):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df_col)\n",
    "    return le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query('select * from {table}'.format(table=table),disk_engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "time_cols = ['AUTHZN_RQST_PROC_TM','PREV_ADR_CHNG_DT','PREV_PMT_DT','PREV_CARD_RQST_DT','FRD_IND_SWT_DT']\n",
    "for c,r in enumerate(df):\n",
    "    tp = df.dtypes[c]\n",
    "#     print tp\n",
    "    if tp == 'object':\n",
    "        if r not in time_cols:\n",
    "            encoders[r] = encode_column(df[r])\n",
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_encoders(table,disk_engine):\n",
    "    df = pd.read_sql_query('select * from {table}'.format(table=table),disk_engine)\n",
    "    df.head()\n",
    "    encoders = {}\n",
    "    time_cols = ['AUTHZN_RQST_PROC_TM','PREV_ADR_CHNG_DT','PREV_PMT_DT','PREV_CARD_RQST_DT','FRD_IND_SWT_DT']\n",
    "    for c,r in enumerate(df):\n",
    "        tp = df.dtypes[c]\n",
    "    #     print tp\n",
    "        if tp == 'object':\n",
    "            if r not in time_cols:\n",
    "                encoders[r] = encode_column(df[r])\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = set()\n",
    "cnt = 0\n",
    "head = 0\n",
    "tail = len(df_ds_u.acct_id)-1\n",
    "batch_size = tail\n",
    "for i in range(batch_size):\n",
    "    \n",
    "    if cnt<usr_ratio:\n",
    "        users.add(df_ds_u.acct_id[head])\n",
    "        cnt+=1\n",
    "        head+=1\n",
    "    else:\n",
    "        users.add(df_ds_u.acct_id[tail])\n",
    "        tail-=1\n",
    "        cnt=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_df(df,encoders):\n",
    "    for col in encoders.keys():\n",
    "        try: \n",
    "            df[col] = encoders[col].transform(df[col])\n",
    "        except:\n",
    "            print 'EXCEPTION'\n",
    "            display(df[col])\n",
    "            print col \n",
    "            raise\n",
    "    for col in time_cols:\n",
    "        df[col] = pd.to_numeric(pd.to_datetime(df[col],errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_info(user,table):\n",
    "    if user == '.':\n",
    "        user = '\".\"'\n",
    "    df_u = pd.read_sql_query('select * from {table} where acct_id = {user}'.format(table=table,user=user),disk_engine)\n",
    "    return df_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_last_date(df_u,cuttoff_date):\n",
    "#     print \"Before Trim\"\n",
    "#     display(df_u)\n",
    "    df_trim = df_u[df_u['FRD_IND_SWT_DT'] >= pd.to_numeric(pd.Series(pd.to_datetime(cuttoff_date)))[0]]\n",
    "#     print \"After Trim\"\n",
    "#     display(df_trim)\n",
    "    ### a historicly later transaction may have been confirmed earlier than a historicly preceeding T\n",
    "    df_trim = df_trim.sort_values('AUTHZN_RQST_PROC_TM',ascending=True,inplace=False)\n",
    "    df_trim = df_trim.reset_index(drop=True)\n",
    "#     print \"After Reorder\"\n",
    "#     display(df_trim)\n",
    "#     display(df_trim)\n",
    "    if not df_trim.empty:\n",
    "#         print 'value to be returned',df_trim['AUTHZN_RQST_PROC_TM'][0]\n",
    "        return df_trim['AUTHZN_RQST_PROC_TM'][0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    query = ['select AUTHZN_RQST_PROC_TM '\n",
    "        'from {table} '\n",
    "        'where FRD_IND_SWT_DT >=' \n",
    "             '\"',\n",
    "        cutt_off_date,\n",
    "             '\" '\n",
    "        'order by AUTHZN_RQST_PROC_TM limit 1 '\n",
    "        ]\n",
    "    query = ''.join(query)\n",
    "    query = query.format(table=table)\n",
    "    dataFrame = pd.read_sql_query(query\n",
    "                       .format(table=table), disk_engine)\n",
    "    dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_col_id(col,df):\n",
    "    col_list = list(df.columns.values)\n",
    "    col_list.remove('index')\n",
    "    col_list.index(col)\n",
    "    \n",
    "def generate_sequence(user,table,encoders,cuttoff_date='2014-05-11'):\n",
    "    df_u = get_user_info(user,table)\n",
    "    unav_cols = ['AUTHZN_APPRL_CD','TSYS_DCLN_REAS_CD','AUTHZN_RESPNS_CD','AUTHZN_APPRD_AMT',]\n",
    "    nan_rpl = ['AUTHZN_APPRL_CD',]\n",
    "    for col in unav_cols:\n",
    "        df_u[col] = df_u[col].shift(1)\n",
    "        loc = list(df_u.columns.values).index(col)\n",
    "        if(col in nan_rpl):\n",
    "            df_u.iloc[0,loc] = 'nan'\n",
    "        else:\n",
    "            df_u.iloc[0,loc] = pad_val\n",
    "#     print df_u.count()\n",
    "#     display(df_u.head())\n",
    "#     display(df_u.sort_values('AUTHZN_RQST_PROC_TM',ascending=True))\n",
    "    encode_df(df_u,encoders)\n",
    "#     print df_u.count()\n",
    "#     display(df_u.head())\n",
    "#     display(df_u.sort_values('AUTHZN_RQST_PROC_TM',ascending=True))\n",
    "    df_u = df_u.sort_values('AUTHZN_RQST_PROC_TM',ascending=True)\n",
    "#     display(df_u[df_u['FRD_IND_SWT_DT'].isnull()])\n",
    "    df_u = df_u.drop('index', axis=1)\n",
    "#     display(df_u[df_u['FRD_IND_SWT_DT'] < pd.to_numeric(pd.Series(pd.to_datetime(cuttoff_date)))[0]].head(8))\n",
    "### This is the last date, before which transaction will be used for trainning. \n",
    "### It coresponds to the date when the last knwon fraudulent transaction was confirmed\n",
    "    last_date_num = get_last_date(df_u,cuttoff_date)\n",
    "    if last_date_num == None:\n",
    "        train = np.array(df_u)\n",
    "#         print \"No cutt offs\"\n",
    "#         print train[:,0:-2].shape\n",
    "#         print \"labels\"\n",
    "#         print train[:,-2].shape\n",
    "        return train[:,0:-2],[],train[:,-2],[]\n",
    "    else:\n",
    "        df_train = df_u[df_u['AUTHZN_RQST_PROC_TM'] < last_date_num]\n",
    "        df_test = df_u[df_u['AUTHZN_RQST_PROC_TM'] >= last_date_num]\n",
    "        print 'train/test split:',np.array(df_train).shape[0],np.array(df_test).shape[0]\n",
    "#     display(df_train)\n",
    "#     display(df_test)\n",
    "#     print 'is this running at all?!',df_test\n",
    "        \n",
    "    train = np.array(df_train)\n",
    "    test = np.array(df_test)\n",
    "\n",
    "#     print train\n",
    "#     print test\n",
    "#     print \"Shapes\"\n",
    "#     print train.shape\n",
    "#     print test.shape\n",
    "#     print \"features\"\n",
    "\n",
    "#     print train[:,0:-2].shape\n",
    "#     print test[:,0:-2].shape \n",
    "#     print \"labels\"\n",
    "#     print train[:,-2].shape\n",
    "#     print test[:,-2].shape \n",
    "    return train[:,0:-2],test[:,0:-2],train[:,-2],test[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user = '128237902'\n",
    "table = 'data_trim'\n",
    "encoders = encoders\n",
    "train,test,y,y_tes = generate_sequence(user,table,encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc = list(df.columns.values).index('AUTHZN_APPRL_CD')\n",
    "df.iloc[0,loc] = 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.TSYS_DCLN_REAS_CD.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[:,1] = np.roll(train[:,1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_roll_values(array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(col_list[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.array_split(X_train_S[0:2], 5)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map(lambda x: len(x),X_train_S[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split_seq = map(lambda x: np.array_split(x,math.ceil(len(x)/50.0)) if len(x)>50 else [x],X_train_S[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "172%50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map(lambda x: len(x),split_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(map(lambda x: reduce(lambda y,z: np.vstack([y,z]),x),split_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened = [sequence for user_seq in split_seq for sequence in user_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map(lambda x: len(x),flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks_lens = map(lambda x: len(x),flattened)\n",
    "chunks_lens[5] = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cnk in chunks_lens:\n",
    "    assert cnk < 50, 'Sequence chunks are exceeding the max_len of {}'.format(seq_len_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_try = np.array([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###has to be float!!!!!!!!!!\n",
    "seq_len_param = 60.0\n",
    "def chunck_seq(seq_list,seq_len=seq_len_param):\n",
    "    split_seq = map(lambda x: np.array_split(x,math.ceil(len(x)/seq_len)) if len(x)>seq_len else [x],seq_list)\n",
    "    flattened = [sequence for user_seq in split_seq for sequence in user_seq]\n",
    "    assert sum(map(lambda x: len(x),flattened)) == sum(map(lambda x: len(x),seq_list))\n",
    "    chunks_lens = map(lambda x: len(x),flattened)\n",
    "    for cnk in chunks_lens:\n",
    "        assert cnk <= seq_len_param, 'Sequence chunks are exceeding the max_len of {} \\n {}'.format(seq_len_param,chunks_lens)\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pad_chunk = keras.preprocessing.sequence.pad_sequences(chunck_seq(X_train_S[0:10]), maxlen=int(seq_len_param),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pad_chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_pad = keras.preprocessing.sequence.pad_sequences(X_train_S, maxlen=None,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_S[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_pad[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    X_train_S = []\n",
    "    X_test_S = []\n",
    "    y_train_S =[]\n",
    "    y_test_S = []\n",
    "    print \"Number of users:\",len(users)\n",
    "    for user in users:\n",
    "    #     if user != '337018623': \n",
    "    #         continue\n",
    "        X_train,X_test,y_train,y_test = generate_sequence(user,'data_trim',encoders)\n",
    "        X_train_S.append(X_train)\n",
    "        X_test_S.append(X_test) \n",
    "        y_train_S.append(y_train)\n",
    "        y_test_S.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sample_w(y_true,class_weight):\n",
    "    shps = y_true.shape\n",
    "    sample_w = []\n",
    "    for i in range(shps[0]):\n",
    "        sample_w.append([])\n",
    "        for j in range(shps[1]):\n",
    "            sample_w[i].append(class_weight[y_true[i,j,0]])\n",
    "    return np.asarray(sample_w)\n",
    "def sequence_generator(users,encoders,mode='train',table='data_trim',class_weight=None):\n",
    "    X_train_S = []\n",
    "    X_test_S = []\n",
    "    y_train_S =[]\n",
    "    y_test_S = []\n",
    "    print \"Number of users:\",len(users)\n",
    "    for user in users:\n",
    "    #     if user != '337018623': \n",
    "    #         continue\n",
    "        X_train,X_test,y_train,y_test = generate_sequence(user,table,encoders)\n",
    "        X_train_S.append(X_train)\n",
    "        X_test_S.append(X_test) \n",
    "        y_train_S.append(y_train)\n",
    "        y_test_S.append(y_test)\n",
    "    #     break\n",
    "    X_test_S = filter(lambda a: a != [], X_test_S)\n",
    "    y_test_S = filter(lambda a: a != [], y_test_S)\n",
    "    if mode =='train':\n",
    "        # chuncked = chunck_seq(X_train_S)\n",
    "        # assert \n",
    "        X_train_pad = keras.preprocessing.sequence.pad_sequences(chunck_seq(X_train_S), maxlen=int(seq_len_param),dtype='float32',value=pad_val)\n",
    "        y_train_S = keras.preprocessing.sequence.pad_sequences(np.array(chunck_seq(y_train_S)), maxlen=int(seq_len_param),dtype='float32',value=lbl_pad_val)\n",
    "        y_train_S = np.expand_dims(y_train_S, -1)\n",
    "        if class_weight != None:\n",
    "\n",
    "            sample_w = generate_sample_w(y_train_S,class_weight)\n",
    "            return X_train_pad,y_train_S,sample_w\n",
    "#         print y_train_S\n",
    "#         print y_train_S.shape\n",
    "#         y_train_S = to_categorical(y_train_S,3)\n",
    "        return X_train_pad,y_train_S\n",
    "    else:\n",
    "        print 'len test',len(X_test_S)\n",
    "        X_test_S_pad = keras.preprocessing.sequence.pad_sequences(chunck_seq(X_test_S), maxlen=int(seq_len_param),dtype='float32',value=pad_val)\n",
    "        y_test_S = keras.preprocessing.sequence.pad_sequences(np.array(chunck_seq(y_test_S)),maxlen=int(seq_len_param),dtype='float32',value=lbl_pad_val)\n",
    "        y_test_S = np.expand_dims(y_test_S, -1)\n",
    "        if class_weight != None:\n",
    "            sample_w = generate_sample_w(y_train_S,class_weight)\n",
    "            return X_train_pad,y_train_S,sample_w\n",
    "        return X_test_S_pad,y_test_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1,[],[],1,2,3,21,1]\n",
    "filter(lambda x:x !=[],a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "math.ceil(1.0*seq_len/seq_len_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = 'data_little'\n",
    "dataFrame_count = pd.read_sql_query('select acct_id, count(*) as num_trans '\n",
    "                       'from {table} '\n",
    "                       'group by acct_id '\n",
    "                        'order by -num_trans'\n",
    "                       .format(table=table), disk_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_count_table(table,disk_engine,cutt_off_date,trans_mode):\n",
    "    query = ['select acct_id,count(*) '\n",
    "        'as num_trans from {table} '\n",
    "        'where AUTHZN_RQST_PROC_TM <= '\n",
    "        '(select AUTHZN_RQST_PROC_TM '\n",
    "        'from {table} '\n",
    "        'where FRD_IND_SWT_DT >=' \n",
    "             '\"',\n",
    "        cutt_off_date,\n",
    "             '\" '\n",
    "        'order by AUTHZN_RQST_PROC_TM limit 1) '\n",
    "        'group by acct_id order by num_trans']\n",
    "    query = ''.join(query)\n",
    "    query = query.format(table=table)\n",
    "    print trans_mode\n",
    "    if trans_mode == 'test':\n",
    "        print 'replaced'\n",
    "        query = query.replace('<=','>')\n",
    "    dataFrame = pd.read_sql_query(query\n",
    "                       .format(table=table), disk_engine)\n",
    "    display(dataFrame)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trans_num_table(table,disk_engine,mode='train',cutt_off_date='2014-05-11',trans_mode='train'):\n",
    "#     dataFrame_acc = pd.read_sql_query('select distinct acct_id, FRD_IND '\n",
    "#                        'from {table} '\n",
    "#                        'order by FRD_IND'.format(table=table), disk_engine)\n",
    "# #     dataFrame = pd.read_sql_query('select acct_id, count(*) as num_trans '\n",
    "# #                        'from {table} '\n",
    "# #                        'group by acct_id '\n",
    "# #                         'order by num_trans'\n",
    "# #                        .format(table=table), disk_engine)\n",
    "\n",
    "    dataFrame = get_count_table(table,disk_engine,cutt_off_date,trans_mode)\n",
    "    u_list = set(dataFrame.acct_id)\n",
    "    \n",
    "    user_tr,user_ts = train_test_split(list(u_list), test_size=0.33, random_state=42)\n",
    "\n",
    "    total_t =0\n",
    "    if mode == 'train':\n",
    "        users = user_tr\n",
    "    else:\n",
    "        users = user_ts\n",
    "    \n",
    "    total_t = total_trans_batch(users,dataFrame)\n",
    "    return math.ceil(total_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans_num_table('data_trim',disk_engine,mode='train',cutt_off_date='2014-05-11',trans_mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    cutt_off_date='2014-05-11'\n",
    "    query = ['select acct_id,count(*) '\n",
    "        'as num_trans from {table} '\n",
    "        'where AUTHZN_RQST_PROC_TM < '\n",
    "        '(select AUTHZN_RQST_PROC_TM '\n",
    "        'from {table} '\n",
    "        'where FRD_IND_SWT_DT >='\n",
    "             '\"',\n",
    "        cutt_off_date,\n",
    "             '\" '\n",
    "        'order by AUTHZN_RQST_PROC_TM limit 1) '\n",
    "        'group by acct_id order by num_trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = ''.join(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query.replace('<','>=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query.format(table='data_trim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_num_table('data_little',disk_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = 'data_little'\n",
    "dataFrame_count = pd.read_sql_query('select acct_id, count(*) as num_trans '\n",
    "                       'from {table} '\n",
    "                       'group by acct_id '\n",
    "                        'order by -num_trans'\n",
    "                       .format(table=table), disk_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def total_trans_batch(users,dataFrame_count):\n",
    "    num_trans = 0\n",
    "    users = set(users)\n",
    "    for user in users:\n",
    "        num_trans+=get_num_trans(user,dataFrame_count)\n",
    "    return num_trans\n",
    "\n",
    "def get_num_trans(user,dfc):\n",
    "    try:\n",
    "        df = dfc[dfc['acct_id']==user]\n",
    "        if df.empty:\n",
    "            print \" user not existing in the table\",user\n",
    "            seq_len = 0\n",
    "        else:\n",
    "            seq_len = dfc[dfc['acct_id']==user].values[0][1]\n",
    "    except:\n",
    "        display(dfc.head(5))\n",
    "        print dfc[dfc['acct_id']==user]\n",
    "        raise\n",
    "    return math.ceil(1.0*seq_len/seq_len_param)\n",
    "\n",
    "def add_user(index,u_list,dataFrame_count,users):\n",
    "    cnt_trans = 0\n",
    "    user = u_list[index]\n",
    "    if user not in users:\n",
    "        users.add(user)\n",
    "        return get_num_trans(user,dataFrame_count)\n",
    "    else:\n",
    "        return 0\n",
    "def user_generator(disk_engine,table='data_trim',batch_size=50,usr_ratio=80,\n",
    "                   mode='train',cutt_off_date='2014-05-11',trans_mode='train',sub_sample=None):\n",
    "\n",
    "\n",
    "    dataFrame_count = get_count_table(table,disk_engine,cutt_off_date,trans_mode)\n",
    "    \n",
    "#     display(dataFrame_count.head(5)) \n",
    "    print \"User List acquired\"\n",
    "    u_list = list(dataFrame_count.acct_id)\n",
    "#     u_list.extend(list(dataFrame_Y.acct_id))\n",
    "    print 'total # users:',len(u_list)\n",
    "    u_set = set(u_list)\n",
    "    print 'total # unique users:',len(u_set) \n",
    "    user_tr,user_ts = train_test_split(list(u_set), test_size=0.33, random_state=42)\n",
    "    print 'total # sequences:',total_trans_batch(list(u_set),dataFrame_count)\n",
    "    if mode == 'train':\n",
    "        u_list =  user_tr\n",
    "    else:\n",
    "        u_list =  user_ts\n",
    "    if trans_mode == 'test':\n",
    "        print 'used # sequences: value is inaccurate, please implement'\n",
    "        print 'used # sequences:',total_trans_batch(u_list,dataFrame_count)                         \n",
    "#     display(dataFrame.acct_id)\n",
    "    \n",
    "    u_list = list(set(u_list))\n",
    "    print 'return set cardinality:',len(u_list)\n",
    "    cnt = 0\n",
    "    head = 0\n",
    "    tail = len(u_list)-1\n",
    "    u_list_all = u_list\n",
    "    while True:\n",
    "        users = set()\n",
    "        cnt_trans = 0\n",
    "        if sub_sample != None:\n",
    "            assert sub_sample<len(u_list_all), 'sub_sample size select is {sub_sample}, but there are only {us} users'.format(sub_sample=sub_sample,us=len(u_list_all))\n",
    "            u_list = np.random.choice(u_list_all, sub_sample,replace=False)\n",
    "            ### reset tail value, to avoid outof bounds exception\n",
    "            tail = len(u_list)-1\n",
    "        while cnt_trans<batch_size:\n",
    "            \n",
    "            if cnt<usr_ratio:\n",
    "                cnt_trans+=add_user(head,u_list,dataFrame_count,users)\n",
    "                cnt+=1\n",
    "                head+=1\n",
    "\n",
    "            else:\n",
    "                cnt_trans+=add_user(tail,u_list,dataFrame_count,users)\n",
    "                tail-=1\n",
    "                cnt=0\n",
    "#             print 'head',head\n",
    "#             print 'tail',tail\n",
    "#             print 'cnt_trans',cnt_trans\n",
    "            if head == tail+1:\n",
    "                    head = 0\n",
    "                    tail = len(u_list)-1\n",
    "                    cnt_trans = 0\n",
    "                    cnt = 0\n",
    "                    #if you have go through all users - return in order not to overfill epoch\n",
    "                    #the same logic could have been achieved with break and without the yield line\n",
    "                    print \"##########ALL COVERED##########\"\n",
    "                    yield users\n",
    "                    users = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\",60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_gen = user_generator(disk_engine,table='data_trim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_gen = user_generator(disk_engine,table='data_trim')\n",
    "for i in range(4):\n",
    "    total_trans = 0\n",
    "    for i in range(int(math.floor(484/seq_len_param))-1):\n",
    "        t_num =total_trans_batch(next(user_gen),dataFrame_count)\n",
    "        print t_num\n",
    "        total_trans += t_num\n",
    "    print \"###########TOTAL\",total_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User List acquired\n",
      "total # users: 478\n",
      "total # unique users: 478\n",
      "total # sequences: 653.0\n",
      "return set cardinality: 320\n",
      "##########ALL COVERED##########\n",
      "11.0\n",
      "##########ALL COVERED##########\n",
      "19.0\n",
      "##########ALL COVERED##########\n",
      "14.0\n",
      "##########ALL COVERED##########\n",
      "29.0\n",
      "##########ALL COVERED##########\n",
      "18.0\n"
     ]
    }
   ],
   "source": [
    "epoch_smpls = [] \n",
    "sample_num = 10\n",
    "seq_len_param = 60.0\n",
    "table = 'data_trim'\n",
    "dataFrame_count = get_count_table(table,disk_engine,cutt_off_date,trans_mode)\n",
    "# dataFrame_count = pd.read_sql_query('select acct_id, count(*) as num_trans '\n",
    "#                        'from {table} '\n",
    "#                        'group by acct_id '\n",
    "#                         'order by -num_trans'\n",
    "#                        .format(table=table), disk_engine)\n",
    "user_gen = user_generator(disk_engine,table=table,sub_sample=50)\n",
    "for i in range(5):\n",
    "    total_trans = 0\n",
    "    while total_trans < sample_num:\n",
    "        t_num =total_trans_batch(next(user_gen),dataFrame_count)\n",
    "        print t_num\n",
    "        total_trans += t_num\n",
    "    epoch_smpls.append(total_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.0, 19.0, 14.0, 29.0, 18.0]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_smpls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(dataFrame_count.sum())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataFrame_Y = pd.read_sql_query('select acct_id, FRD_IND, count(*) as num_trans '\n",
    "                       'from {table} '\n",
    "                       'where FRD_IND=\"Y\"'\n",
    "                       'group by acct_id '\n",
    "                        'order by -num_trans'\n",
    "                       .format(table=table), disk_engine)\n",
    "display(dataFrame_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataFrame_count = pd.read_sql_query('select acct_id, count(*) as num_trans '\n",
    "                       'from {table} '\n",
    "                       'group by acct_id '\n",
    "                        'order by -num_trans'\n",
    "                       .format(table=table), disk_engine)\n",
    "dataFrame_count[dataFrame_count['acct_id']=='70557011'].values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "def data_generator(user_mode,trans_mode,disk_engine,encoders,table,\n",
    "                   batch_size=400,usr_ratio=80,class_weight=None,lbl_pad_val = 2,\n",
    "                   pad_val = -1,cutt_off_date='2014-05-11',sub_sample=None,epoch_size=None):\n",
    "    user_gen = user_generator(disk_engine,usr_ratio=usr_ratio,batch_size=batch_size,table=table,mode=user_mode,trans_mode=trans_mode,sub_sample=sub_sample)\n",
    "    print \"Users generator\"\n",
    "    last_date = get_last_date(cutt_off_date,table,disk_engine)\n",
    "    print 'last_date calculated!'\n",
    "    x_acc = []\n",
    "    y_acc = []\n",
    "    sample_w = []\n",
    "    total_eg = 0\n",
    "    while True:\n",
    "        users = next(user_gen)\n",
    "        outs = sequence_generator(users,encoders,disk_engine,lbl_pad_val,pad_val,last_date,mode=trans_mode,table=table,class_weight=class_weight)\n",
    "        \n",
    "        if not(epoch_size == None):\n",
    "            while True:\n",
    "                num_seq = outs[0].shape[0]\n",
    "                print 'num_Seq',num_seq\n",
    "               \n",
    "                remain = epoch_size - (total_eg + num_seq)\n",
    "                print '{remain} = {epoch_size} - ({total_eg}+{num_seq})'.format(remain=remain,epoch_size=epoch_size,total_eg=total_eg,num_seq=num_seq)   \n",
    "                print 'remain',remain\n",
    "                if remain >=0:\n",
    "                    total_eg +=num_seq\n",
    "                    yield outs\n",
    "                else:\n",
    "                    ### remain <0 => num_seq - remain\n",
    "                    cutline = num_seq + remain\n",
    "                    temp = []\n",
    "                    for i in range(len(outs)):\n",
    "                        temp.append(outs[i][0:cutline])\n",
    "                    yield tuple(temp)\n",
    "                    ####end of epoch!\n",
    "\n",
    "                    total_eg = 0\n",
    "                    temp = []\n",
    "                    for i in range(len(outs)):\n",
    "                        temp.append(outs[0][cutline:])\n",
    "                    outs =  tuple(temp) \n",
    "                if remain >=0:\n",
    "                    break\n",
    "        else:    \n",
    "            yield outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "def inside(t):\n",
    "    yield t+1\n",
    "    yield t+2\n",
    "def outside(t):\n",
    "    inner = inside(t)\n",
    "    while True:\n",
    "        yield next(inner)\n",
    "        t*=10\n",
    "gen_test = outside(5)\n",
    "print next(gen_test)\n",
    "print next(gen_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users generator\n",
      "0    1398712475000000000\n",
      "Name: AUTHZN_RQST_PROC_TM, dtype: int64\n",
      "last_date calculated!\n",
      "User List acquired\n",
      "total # users: 1840\n",
      "total # unique users: 1840\n",
      "total # sequences: 2763.0\n",
      "return set cardinality: 1232\n",
      "##########ALL COVERED##########\n",
      "Number of users: 80\n",
      "num_Seq 121\n",
      "-91 = 30 - (0+121)\n",
      "remain -91\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 1)\n",
      "s (30, 60)\n",
      "num_Seq 91\n",
      "-61 = 30 - (0+91)\n",
      "remain -61\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 44)\n",
      "s (30, 60, 44)\n",
      "num_Seq 61\n",
      "-31 = 30 - (0+61)\n",
      "remain -31\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 44)\n",
      "s (30, 60, 44)\n",
      "num_Seq 31\n",
      "-1 = 30 - (0+31)\n",
      "remain -1\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 44)\n",
      "s (30, 60, 44)\n",
      "num_Seq 1\n",
      "29 = 30 - (0+1)\n",
      "remain 29\n",
      "X (1, 60, 44)\n",
      "y (1, 60, 44)\n",
      "s (1, 60, 44)\n",
      "##########ALL COVERED##########\n",
      "Number of users: 80\n",
      "num_Seq 121\n",
      "-92 = 30 - (1+121)\n",
      "remain -92\n",
      "X (29, 60, 44)\n",
      "y (29, 60, 1)\n",
      "s (29, 60)\n",
      "num_Seq 92\n",
      "-62 = 30 - (0+92)\n",
      "remain -62\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 44)\n",
      "s (30, 60, 44)\n",
      "num_Seq 62\n",
      "-32 = 30 - (0+62)\n",
      "remain -32\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 44)\n",
      "s (30, 60, 44)\n",
      "num_Seq 32\n",
      "-2 = 30 - (0+32)\n",
      "remain -2\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 44)\n",
      "s (30, 60, 44)\n",
      "num_Seq 2\n",
      "28 = 30 - (0+2)\n",
      "remain 28\n",
      "X (2, 60, 44)\n",
      "y (2, 60, 44)\n",
      "s (2, 60, 44)\n",
      "##########ALL COVERED##########\n",
      "Number of users: 80\n",
      "num_Seq 121\n",
      "-93 = 30 - (2+121)\n",
      "remain -93\n",
      "X (28, 60, 44)\n",
      "y (28, 60, 1)\n",
      "s (28, 60)\n",
      "num_Seq 93\n",
      "-63 = 30 - (0+93)\n",
      "remain -63\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 44)\n",
      "s (30, 60, 44)\n",
      "num_Seq 63\n",
      "-33 = 30 - (0+63)\n",
      "remain -33\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 44)\n",
      "s (30, 60, 44)\n",
      "num_Seq 33\n",
      "-3 = 30 - (0+33)\n",
      "remain -3\n",
      "X (30, 60, 44)\n",
      "y (30, 60, 44)\n",
      "s (30, 60, 44)\n",
      "num_Seq 3\n",
      "27 = 30 - (0+3)\n",
      "remain 27\n",
      "X (3, 60, 44)\n",
      "y (3, 60, 44)\n",
      "s (3, 60, 44)\n"
     ]
    }
   ],
   "source": [
    "user_mode = 'train'\n",
    "trans_mode = 'train'\n",
    "data_gen =  data_generator(user_mode,trans_mode,disk_engine,encoders,table='data_little',class_weight=class_weight,batch_size=400,sub_sample=80,epoch_size=30)\n",
    "for i in range(15):\n",
    "    X,y,s = next(data_gen)\n",
    "    print 'X',X.shape\n",
    "    print 'y',y.shape\n",
    "    print 's',s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %debug\n",
    "X_train_pad,y_train_S,sample_w = next(data_gen)\n",
    "print X_train_pad.shape\n",
    "print y_train_S.shape\n",
    "print sample_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %debug\n",
    "X_train_pad,y_train_S,sample_w = next(data_gen)\n",
    "print X_train_pad.shape\n",
    "print y_train_S.shape\n",
    "print sample_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train_pad[-1]\n",
    "print y_train_S[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, LSTM, TimeDistributed, Masking\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_dim = 200\n",
    "num_layers = 1\n",
    "optimizer=keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-08)\n",
    "table = 'data_little'\n",
    "samples_per_epoch = math.ceil(trans_num_table(table,disk_engine)*0.67)\n",
    "nb_epoch = 100\n",
    "lbl_pad_val = 2\n",
    "pad_val = -1\n",
    "class_weight = {0 : 1.,\n",
    "               1: 10.,\n",
    "               2: 0.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoders = populate_encoders(table,disk_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(seq_len_param, 44),name='main_input')\n",
    "mask = Masking(mask_value=pad_val)(input_layer)\n",
    "prev = GRU(hidden_dim,#input_length=50,\n",
    "                  return_sequences=True,go_backwards=False,stateful=False,\n",
    "                  unroll=False,consume_less='gpu',\n",
    "                  init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "           inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "           b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(mask)\n",
    "# for i in range(num_layers-1):\n",
    "#     prev = GRU(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "#            inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "#            b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n",
    "output_layer = TimeDistributed(Dense(3,activation='softmax'))(prev)\n",
    "model = Model(input=[input_layer],output=[output_layer])\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy','hinge','squared_hinge','binary_accuracy','binary_crossentropy'])\n",
    "              metrics=['accuracy'],\n",
    "             sample_weight_mode=None)\n",
    "data_gen =  data_generator(disk_engine,encoders,table=table)\n",
    "history = model.fit_generator(data_gen, samples_per_epoch, nb_epoch, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, max_q_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_2 = model.fit_generator(data_gen, samples_per_epoch, nb_epoch, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, max_q_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(X_train_pad.shape[0]):\n",
    "    if 1 in (list(y_train_S[i])):\n",
    "        print i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "join_= np.dstack([prediction,y_train_S])\n",
    "df_pred = pd.DataFrame(join_[391])\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 23\n",
    "d = {'target' : pd.Series(np.reshape(y_train_S[index],len(y_train_S[index]))),\n",
    "    'pred' : pd.Series(np.reshape(prediction[index][0],len(prediction[index][0]))),\n",
    "    'pred_2' : pd.Series(np.reshape(prediction[index][1],len(prediction[index][1]))),}\n",
    "df_pred = pd.DataFrame(d)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(50, 44),name='main_input')\n",
    "mask = Masking(mask_value=0)(input_layer)\n",
    "prev = GRU(hidden_dim,#input_length=50,\n",
    "                  return_sequences=True,go_backwards=False,stateful=False,\n",
    "                  unroll=False,consume_less='gpu',\n",
    "                  init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "           inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "           b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(mask)\n",
    "for i in range(num_layers-1):\n",
    "    prev = GRU(hidden_dim,#input_length=50,\n",
    "                  return_sequences=True,go_backwards=False,stateful=False,\n",
    "                  unroll=False,consume_less='gpu',\n",
    "                  init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "           inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "           b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(prev)\n",
    "output_layer = TimeDistributed(Dense(1))(prev)\n",
    "model = Model(input=[input_layer],output=[output_layer])\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "data_gen =  data_generator(disk_engine,encoders,table=table)\n",
    "history = model.fit_generator(data_gen, samples_per_epoch, nb_epoch, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(data_gen, samples_per_epoch, nb_epoch, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print train_test_split(range(10), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print len(X_train_S)\n",
    "print len(X_test_S)\n",
    "print len(y_train_S)\n",
    "print len(y_test_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'.' in users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query('select * '\n",
    "                       'from {table} '.format(table=table), disk_engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df.MRCH_NM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoders['acct_id'].transform(['.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_u = get_user_info(\"'.'\",'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_u= df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_u[df_u['FRD_IND']=='Y'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Timestamp('20120101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_u[df_u['FRD_IND_SWT_DT']>pd.Timestamp('20120101')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_u['AUTHZN_AMT']>10\n",
    "df_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_u[df_u['FRD_IND']=='Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_u['FRD_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_u[df_u['acct_id']=='337018623']['CAVV_CD'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Timestamp('2013-05-11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df_u[df_u['acct_id']=='337018623']['CAVV_CD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le.transform([None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.to_numeric(pd.Series(pd.to_datetime('2013-05-11')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_numeric(pd.Series(pd.to_datetime('2014-05-11')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(10.0)\n",
    "np.array_split(x, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "title = 'dsdssd'\n",
    "with io.open('./data/gs_results.csv', 'a', encoding='utf-8') as output:\n",
    "                            title_csv = title.replace('_',',')+','+str(history.history['acc'][-1])+','+str(history.history['loss'][-1])\n",
    "                            print title_csv\n",
    "                            output.write(unicode(title_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = 'Trainin_Loss'\n",
    "title.replace('Loss','acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "table = 'data_little'\n",
    "encoders = populate_encoders(table,disk_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_generator(user_mode,trans_mode,disk_engine,encoders,table='data_trim',\n",
    "                   batch_size=400,usr_ratio=80,class_weight=None,lbl_pad_val = 2, pad_val = -1):\n",
    "    user_gen = user_generator(disk_engine,usr_ratio=usr_ratio,batch_size=batch_size,table=table,mode=user_mode)\n",
    "    print \"Users generator\"\n",
    "    while True:\n",
    "        users = next(user_gen)\n",
    "        yield sequence_generator(users,encoders,disk_engine,lbl_pad_val,pad_val,mode=trans_mode,table=table,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_trans_generator(disk_engine,encoders,table='data_trim',batch_size=400,usr_ratio=80,class_weight=None,lbl_pad_val = 2, pad_val = -1):\n",
    "    user_gen = user_generator(disk_engine,usr_ratio=usr_ratio,batch_size=batch_size,table=table)\n",
    "    print \"Users generator\"\n",
    "    while True:\n",
    "        users = next(user_gen)\n",
    "        yield sequence_generator(users,encoders,disk_engine,lbl_pad_val,pad_val,mode='test',table=table,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_users_generator(disk_engine,encoders,table='data_trim',batch_size=400,usr_ratio=80,class_weight=None,lbl_pad_val = 2, pad_val = -1):\n",
    "    user_gen = user_generator(disk_engine,usr_ratio=usr_ratio,batch_size=batch_size,table=table,mode='test')\n",
    "    print \"Users generator\"\n",
    "    while True:\n",
    "        users = next(user_gen)\n",
    "        yield sequence_generator(users,encoders,disk_engine,lbl_pad_val,pad_val,mode='train',table=table,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_usertrans_generator(disk_engine,encoders,table='data_trim',batch_size=400,usr_ratio=80,class_weight=None,lbl_pad_val = 2, pad_val = -1):\n",
    "    user_gen = user_generator(disk_engine,usr_ratio=usr_ratio,batch_size=batch_size,table=table,mode='test')\n",
    "    print \"Users generator\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_gen = eval_trans_generator(disk_engine,encoders,table=table,batch_size=400,usr_ratio=80,class_weight=None)\n",
    "X_test_pad,y_test_S = next(test_gen)\n",
    "print X_test_pad.shape\n",
    "print y_test_S.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_gen = eval_users_generator(disk_engine,encoders,table=table,batch_size=400,usr_ratio=80,class_weight=None)\n",
    "X_test_pad,y_test_S = next(test_gen)\n",
    "print X_test_pad.shape\n",
    "print y_test_S.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_mode = 'test'\n",
    "trans_mode = 'train'\n",
    "table = 'data_more'\n",
    "test_gen = eval_generator(user_mode,trans_mode,disk_engine,encoders,table=table,batch_size=400,usr_ratio=80,class_weight=None)\n",
    "X_test_pad,y_test_S = next(test_gen)\n",
    "print X_test_pad.shape\n",
    "print y_test_S.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Users generator\n",
    "User List acquired\n",
    "List lens: df- 1912  count- 1888\n",
    "total # users: 1912\n",
    "total # unique users: 1888\n",
    "total # transactions: 1959.0\n",
    "return set cardinality: 1264\n",
    "return list length: 248\n",
    "Number of users: 248\n",
    "(437, 60, 44)\n",
    "(437, 60, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn = 'lstm'\n",
    "hidden_dim = 300\n",
    "num_layers = 3\n",
    "lr= 1e-3\n",
    "nb_epoch = 13\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=lr, rho=0.9, epsilon=1e-08)\n",
    "\n",
    "\n",
    "title = 'Training_Loss'+'_'+rnn.upper()+'_'+str(hidden_dim)+'_'+str(num_layers)+'_'+str(type(optimizer).__name__)+'_'+str(lr)\n",
    "print title\n",
    "input_layer = Input(shape=(int(seq_len_param), 44),name='main_input')\n",
    "mask = Masking(mask_value=0)(input_layer)\n",
    "if rnn == 'gru':\n",
    "    prev = GRU(hidden_dim,#input_length=50,\n",
    "                        return_sequences=True,go_backwards=False,stateful=False,\n",
    "                        unroll=False,consume_less='gpu',\n",
    "                        init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "                inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "                b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(mask)\n",
    "else:\n",
    "    prev = LSTM(hidden_dim, return_sequences=True,go_backwards=False,stateful=False,\n",
    "        init='glorot_uniform', inner_init='orthogonal', \n",
    "        forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid',\n",
    "        W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(mask)\n",
    "for i in range(num_layers-1):\n",
    "    if rnn == 'gru':\n",
    "        prev = GRU(hidden_dim,#input_length=50,\n",
    "                            return_sequences=True,go_backwards=False,stateful=False,\n",
    "                            unroll=False,consume_less='gpu',\n",
    "                            init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "                    inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "                    b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(prev)\n",
    "    else:\n",
    "        prev = LSTM(hidden_dim, return_sequences=True,go_backwards=False,stateful=False,\n",
    "            init='glorot_uniform', inner_init='orthogonal', \n",
    "            forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid',\n",
    "            W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(prev)\n",
    "output_layer = TimeDistributed(Dense(3,activation='softmax'))(prev)\n",
    "model = Model(input=[input_layer],output=[output_layer])\n",
    "model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "data_gen =  data_generator(disk_engine,encoders,table=table)\n",
    "history = model.fit_generator(data_gen, samples_per_epoch, nb_epoch, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(data_gen, samples_per_epoch, 3, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ccfd_dnn.proto import compile_seq2seq_RNN\n",
    "from ccfd_dnn.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 1\n",
    "table = 'data_little'\n",
    "samples_per_epoch = 1959\n",
    "model = compile_seq2seq_RNN(rnn = 'gru', hidden_dim = 300, num_layers = 3, lbl_pad_val = 2, pad_val = -1, optimizer = keras.optimizers.RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08))\n",
    "\n",
    "data_gen =  data_generator(disk_engine,encoders,table=table)\n",
    "history = model.fit_generator(data_gen, samples_per_epoch, nb_epoch, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pad_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_samples = 400\n",
    "eval_gen = eval_users_generator(disk_engine,encoders,table=table,\n",
    "                     batch_size=400,usr_ratio=80,class_weight=None)\n",
    "model.evaluate_generator(eval_gen, val_samples, max_q_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC evaluation auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_samples = 180\n",
    "# model.predict_generator(eval_gen, val_samples, max_q_size=10000)\n",
    "samples = 0\n",
    "eval_gen = eval_users_generator(disk_engine,encoders,table=table,\n",
    "                     batch_size=400,usr_ratio=80,class_weight=None)\n",
    "for batch in eval_gen:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_samples = 1\n",
    "outs = model.predict_generator(eval_gen, val_samples, max_q_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_gen = eval_users_generator(disk_engine,encoders,table=table,\n",
    "                     batch_size=400,usr_ratio=80,class_weight=None)\n",
    "x,y = next(eval_gen)\n",
    "y_hat = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_gen = data_generator(disk_engine,encoders,table=table,\n",
    "                     batch_size=400,usr_ratio=80,class_weight=None)\n",
    "x,y = next(eval_gen)\n",
    "y_hat = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y.shape\n",
    "print y_hat.shape\n",
    "print y_r.shape\n",
    "print y_hat_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "y_r = y.ravel()\n",
    "y_hat_r = y_hat[:,:,1].ravel()\n",
    "pad_ids = np.where(y_r!=2)\n",
    "fpr,tpr,_ = roc_curve(y_r[pad_ids], y_hat_r[pad_ids])\n",
    "trace = Scatter(x=fpr,y=tpr)\n",
    "data = [trace]\n",
    "title = 'ROC'\n",
    "layout = Layout(title=title, width=800, height=640)\n",
    "fig = Figure(data=data, layout=layout)\n",
    "iplot(fig)\n",
    "auc_val = auc(fpr, tpr)\n",
    "auc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_auc(model,mode,num_sample):\n",
    "    if mode =='train':\n",
    "        gen = data_gen = data_generator(disk_engine,encoders,table=table,\n",
    "                     batch_size=400,usr_ratio=80,class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_gen = data_generator(disk_engine,encoders,table=table,\n",
    "                     batch_size=400,usr_ratio=80,class_weight=None)\n",
    "model.eval_auc_generator(data_gen, 484, max_q_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.engine.training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ccfd_dnn.model import eval_auc_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_gen = eval_users_generator(disk_engine,encoders,table=table,\n",
    "                     batch_size=400,usr_ratio=80,class_weight=None)\n",
    "aucs = eval_auc_generator(model, eval_gen, 978, max_q_size=10000,plt_filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_gen = eval_users_generator(disk_engine,encoders,table=table,\n",
    "                     batch_size=400,usr_ratio=80,class_weight=None)\n",
    "all_outs = eval_auc_generator(model, eval_gen, val_samples, max_q_size=10000,plt_filename=None)\n",
    "print all_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoders['FRD_IND'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.engine.training import *\n",
    "from sklearn.metrics import *\n",
    "def eval_auc_generator(model, generator, val_samples, max_q_size=10000,plt_filename=None,acc=True):\n",
    "    '''Generates predictions for the input samples from a data generator.\n",
    "    The generator should return the same kind of data as accepted by\n",
    "    `predict_on_batch`.\n",
    "\n",
    "    # Arguments\n",
    "        generator: generator yielding batches of input samples.\n",
    "        val_samples: total number of samples to generate from `generator`\n",
    "            before returning.\n",
    "        max_q_size: maximum size for the generator queue\n",
    "\n",
    "    # Returns\n",
    "        Numpy array(s) of predictions.\n",
    "    '''\n",
    "\n",
    "\n",
    "    processed_samples = 0\n",
    "    wait_time = 0.01\n",
    "    all_outs = []\n",
    "    all_y_r = []\n",
    "    all_y_hat = []\n",
    "\n",
    "    data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)\n",
    "\n",
    "    while processed_samples < val_samples:\n",
    "        generator_output = None\n",
    "        while not _stop.is_set():\n",
    "            if not data_gen_queue.empty():\n",
    "                generator_output = data_gen_queue.get()\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "        if isinstance(generator_output, tuple):\n",
    "            if len(generator_output) == 2:\n",
    "                x, y = generator_output\n",
    "                sample_weight = None\n",
    "            elif len(generator_output) == 3:\n",
    "                x, y, sample_weight = generator_output\n",
    "            else:\n",
    "                _stop.set()\n",
    "                raise Exception('output of generator should be a tuple '\n",
    "                                '(x, y, sample_weight) '\n",
    "                                'or (x, y). Found: ' + str(generator_output))\n",
    "        else:\n",
    "            _stop.set()\n",
    "            raise Exception('output of generator should be a tuple '\n",
    "                                '(x, y, sample_weight) '\n",
    "                                'or (x, y). Found: ' + str(generator_output))\n",
    "\n",
    "        try:\n",
    "            y_hat = model.predict_on_batch(x)\n",
    "            y_r = y.ravel()\n",
    "            y_hat_r = y_hat[:,:,1].ravel()\n",
    "            pad_ids = np.where(y_r!=2)\n",
    "            all_y_r.extend(y_r[pad_ids])\n",
    "            all_y_hat.extend(y_hat_r[pad_ids])\n",
    "        except:\n",
    "            _stop.set()\n",
    "            raise\n",
    "        nb_samples = x.shape[0]   \n",
    "\n",
    "        processed_samples += nb_samples\n",
    "\n",
    "    _stop.set()\n",
    "\n",
    "\n",
    "    all_y_r = np.array(all_y_r,dtype=np.dtype(float))\n",
    "    all_y_hat = np.array(all_y_hat,dtype=np.dtype(float))\n",
    "    print all_y_r.shape\n",
    "    print all_y_hat.shape\n",
    "    print '#####################FRAUD TRNAS##################'\n",
    "    print '# fraud transaction',all_y_hat[np.where(all_y_hat==1)].shape\n",
    "    #######ROC CURVE\n",
    "    fpr,tpr,tresholds = roc_curve(all_y_r,all_y_hat)\n",
    "    print all_y_hat\n",
    "    print tresholds\n",
    "    print tresholds.shape\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    print auc_val\n",
    "    ############CLASSIFICATION REPORT########################\n",
    "    target_names = ['Genuine', 'Fraud']\n",
    "    #########Need to determine treshold \n",
    "    all_y_hat[np.where(all_y_hat>=tresholds[1])] = 1\n",
    "    all_y_hat[np.where(all_y_hat<tresholds[1])]  = 0\n",
    "    clc_report = classification_report(all_y_r, all_y_hat, target_names=target_names)\n",
    "    ############Accuracy\n",
    "    acc = accuracy_score(all_y_r,all_y_hat)\n",
    "    if plt_filename != None:\n",
    "        trace = Scatter(x=fpr,y=tpr)\n",
    "        data = [trace]\n",
    "        title = 'ROC'\n",
    "        layout = Layout(title=title, width=800, height=640)\n",
    "        fig = Figure(data=data, layout=layout)\n",
    "        py.image.save_as(fig,filename=plt_filename)\n",
    "    return [auc_val,clc_report,acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    plt_filename= None                    \n",
    "    eval_gen = eval_users_generator(disk_engine,encoders,table=table,\n",
    "                                batch_size=400,usr_ratio=80,class_weight=None,lbl_pad_val = lbl_pad_val, pad_val = pad_val)\n",
    "\n",
    "    \n",
    "    eval_list  = eval_auc_generator(model, eval_gen, val_samples, max_q_size=10000,plt_filename=plt_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter(lambda a: a!=[],[1,2,[],2,2,[]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users generator\n",
      "0    1398712475000000000\n",
      "Name: AUTHZN_RQST_PROC_TM, dtype: int64\n",
      "last_date calculated!\n",
      "User List acquired\n",
      "total # users: 1840\n",
      "total # unique users: 1840\n",
      "total # sequences: 2763.0\n",
      "used # sequences: 884.0\n",
      "return set cardinality: 608\n",
      "Number of users: 277\n",
      "xs shape (400, 60, 44)\n",
      "labels shape (400, 60, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  1.59100000e+03,   1.39764640e+18,   5.90640000e+04, ...,\n",
       "            1.39656957e+18,   1.85080002e+02,   1.39294077e+18],\n",
       "         [  1.59100000e+03,   1.39837291e+18,   5.45270000e+04, ...,\n",
       "            1.39656957e+18,   1.85080002e+02,   1.39294077e+18],\n",
       "         [  1.59100000e+03,   1.39837291e+18,   5.26200000e+03, ...,\n",
       "            1.39656957e+18,   1.85080002e+02,   1.39294077e+18]],\n",
       " \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  1.61500000e+03,   1.39756600e+18,   5.36580000e+04, ...,\n",
       "           -9.22337204e+18,   0.00000000e+00,   1.39518721e+18],\n",
       "         [  1.61500000e+03,   1.39836658e+18,   5.90640000e+04, ...,\n",
       "           -9.22337204e+18,   0.00000000e+00,   1.39518721e+18],\n",
       "         [  1.61500000e+03,   1.39842390e+18,   4.98300000e+04, ...,\n",
       "           -9.22337204e+18,   0.00000000e+00,   1.39518721e+18]],\n",
       " \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [  1.07900000e+03,   1.36794255e+18,   5.90640000e+04, ...,\n",
       "            1.36676154e+18,   6.30200005e+01,   1.33816324e+18],\n",
       "         [  1.07900000e+03,   1.36890311e+18,   5.46660000e+04, ...,\n",
       "            1.36676154e+18,   6.30200005e+01,   1.33816324e+18]],\n",
       " \n",
       "        ..., \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  1.37000000e+03,   1.38829341e+18,   1.64620000e+04, ...,\n",
       "            1.38628804e+18,   2.00000000e+01,   1.37090876e+18],\n",
       "         [  1.37000000e+03,   1.39317909e+18,   5.90640000e+04, ...,\n",
       "            1.39173117e+18,   1.00000000e+01,   1.37090876e+18],\n",
       "         [  1.37000000e+03,   1.39522404e+18,   5.84490000e+04, ...,\n",
       "            1.39432327e+18,   1.00000000e+01,   1.37090876e+18]],\n",
       " \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  1.60500000e+03,   1.39559980e+18,   7.54200000e+03, ...,\n",
       "           -9.22337204e+18,   0.00000000e+00,   1.39466879e+18],\n",
       "         [  1.60500000e+03,   1.39661506e+18,   1.90950000e+04, ...,\n",
       "           -9.22337204e+18,   0.00000000e+00,   1.39466879e+18],\n",
       "         [  1.60500000e+03,   1.39721869e+18,   5.19360000e+04, ...,\n",
       "            1.39708799e+18,   9.40000000e+01,   1.39466879e+18]],\n",
       " \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  1.10400000e+03,   1.38748733e+18,   5.90640000e+04, ...,\n",
       "            1.38386884e+18,   1.80000000e+01,   1.34084165e+18],\n",
       "         [  1.10400000e+03,   1.38866216e+18,   1.95100000e+03, ...,\n",
       "            1.38741119e+18,   2.25000000e+01,   1.34084165e+18],\n",
       "         [  1.10400000e+03,   1.39162328e+18,   4.06700000e+03, ...,\n",
       "            1.38905276e+18,   2.36000004e+01,   1.34084165e+18]]], dtype=float32),\n",
       " array([[[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 2.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        ..., \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]], dtype=float32))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ccfd_dnn.model import *\n",
    "data_gen = data_generator(user_mode,trans_mode,disk_engine,encoders,table=table,\n",
    "                                         batch_size=400,usr_ratio=80,class_weight=None,lbl_pad_val = 2, pad_val = -1)\n",
    "next(data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-7ed0097d7e9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,2,3'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join([str(1),str(2),str(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_function_kwargs': {},\n",
       " '_output_mask_cache': {'139972926101776_139972926060048': Any{2}.0,\n",
       "  '139972926101776_9545840': Any{2}.0},\n",
       " '_output_shape_cache': {'(None, 60, 44)': (None, 60, 3)},\n",
       " '_output_tensor_cache': {'139972926101776_9545840': Reshape{3}.0},\n",
       " 'built': True,\n",
       " 'container_nodes': {'gru_7_ib-0',\n",
       "  'gru_8_ib-0',\n",
       "  'gru_9_ib-0',\n",
       "  'main_input_ib-0',\n",
       "  'masking_3_ib-0',\n",
       "  'timedistributed_3_ib-0'},\n",
       " 'history': <keras.callbacks.History at 0x7f4dc8c1cc50>,\n",
       " 'inbound_nodes': [<keras.engine.topology.Node at 0x7f4def443550>],\n",
       " 'input_layers': [<keras.engine.topology.InputLayer at 0x7f4dfc89d690>],\n",
       " 'input_layers_node_indices': [0],\n",
       " 'input_layers_tensor_indices': [0],\n",
       " 'input_names': ['main_input'],\n",
       " 'inputs': [main_input],\n",
       " 'internal_input_shapes': [(None, 60, 44)],\n",
       " 'internal_output_shapes': [(None, 60, 3)],\n",
       " 'layers': [<keras.engine.topology.InputLayer at 0x7f4dfc89d690>,\n",
       "  <keras.layers.core.Masking at 0x7f4dfc89d990>,\n",
       "  <keras.layers.recurrent.GRU at 0x7f4dfc893690>,\n",
       "  <keras.layers.recurrent.GRU at 0x7f4dedb3e790>,\n",
       "  <keras.layers.recurrent.GRU at 0x7f4dee8a49d0>,\n",
       "  <keras.layers.wrappers.TimeDistributed at 0x7f4def428050>],\n",
       " 'layers_by_depth': {0: [<keras.layers.wrappers.TimeDistributed at 0x7f4def428050>],\n",
       "  1: [<keras.layers.recurrent.GRU at 0x7f4dee8a49d0>],\n",
       "  2: [<keras.layers.recurrent.GRU at 0x7f4dedb3e790>],\n",
       "  3: [<keras.layers.recurrent.GRU at 0x7f4dfc893690>],\n",
       "  4: [<keras.layers.core.Masking at 0x7f4dfc89d990>],\n",
       "  5: [<keras.engine.topology.InputLayer at 0x7f4dfc89d690>]},\n",
       " 'loss': 'sparse_categorical_crossentropy',\n",
       " 'loss_functions': [<function keras.objectives.sparse_categorical_crossentropy>],\n",
       " 'loss_weights': None,\n",
       " 'metrics': [mean],\n",
       " 'metrics_names': ['loss', 'acc'],\n",
       " 'name': 'model_3',\n",
       " 'nodes_by_depth': {0: [<keras.engine.topology.Node at 0x7f4def39fa50>],\n",
       "  1: [<keras.engine.topology.Node at 0x7f4dee6a9950>],\n",
       "  2: [<keras.engine.topology.Node at 0x7f4dee2c2790>],\n",
       "  3: [<keras.engine.topology.Node at 0x7f4dedabf690>],\n",
       "  4: [<keras.engine.topology.Node at 0x7f4dfc8934d0>],\n",
       "  5: [<keras.engine.topology.Node at 0x7f4dfc89d950>]},\n",
       " 'optimizer': <keras.optimizers.RMSprop at 0x7f4dfc89d610>,\n",
       " 'outbound_nodes': [],\n",
       " 'output_layers': [<keras.layers.wrappers.TimeDistributed at 0x7f4def428050>],\n",
       " 'output_layers_node_indices': [0],\n",
       " 'output_layers_tensor_indices': [0],\n",
       " 'output_names': ['timedistributed_3'],\n",
       " 'outputs': [Reshape{3}.0],\n",
       " 'predict_function': <keras.backend.theano_backend.Function at 0x7f4dc982a250>,\n",
       " 'sample_weight_mode': None,\n",
       " 'sample_weight_modes': [None],\n",
       " 'sample_weights': [timedistributed_3_sample_weights],\n",
       " 'stop_training': False,\n",
       " 'supports_masking': False,\n",
       " 'targets': [timedistributed_3_target],\n",
       " 'test_function': <keras.backend.theano_backend.Function at 0x7f4e055cda10>,\n",
       " 'total_loss': Elemwise{mul,no_inplace}.0,\n",
       " 'train_function': <keras.backend.theano_backend.Function at 0x7f4df10dda90>,\n",
       " 'validation_data': None}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': [0, 1],\n",
       " 'history': {'acc': [0.99639272671563706, 0.99828143543342718],\n",
       "  'loss': [0.030823190755963386, 0.021165021918162573]},\n",
       " 'model': <keras.engine.training.Model at 0x7f4def443610>,\n",
       " 'params': {'do_validation': False,\n",
       "  'metrics': ['loss', 'acc', 'val_loss', 'val_acc'],\n",
       "  'nb_epoch': 3,\n",
       "  'nb_sample': 1959,\n",
       "  'verbose': 1}}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users =  \n",
    "np.random.choice(aa_milne_arr, 5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  2.42000000e+02,   1.39394930e+18,   5.90640000e+04, ...,\n",
       "            1.38983039e+18,   9.70000000e+01,   1.36995837e+18],\n",
       "         [  2.42000000e+02,   1.39463869e+18,   1.93390000e+04, ...,\n",
       "            1.38983039e+18,   9.70000000e+01,   1.36995837e+18],\n",
       "         [  2.42000000e+02,   1.39463979e+18,   5.44880000e+04, ...,\n",
       "            1.38983039e+18,   9.70000000e+01,   1.36995837e+18]],\n",
       " \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  6.23000000e+02,   1.39024174e+18,   5.73580000e+04, ...,\n",
       "            1.38913921e+18,   5.00000000e+01,   1.38326397e+18],\n",
       "         [  6.23000000e+02,   1.39090228e+18,   1.81970000e+04, ...,\n",
       "            1.38913921e+18,   5.00000000e+01,   1.38326397e+18],\n",
       "         [  6.23000000e+02,   1.39618295e+18,   5.11260000e+04, ...,\n",
       "            1.39449603e+18,   3.03999996e+01,   1.38326397e+18]],\n",
       " \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  7.65000000e+02,   1.39825306e+18,   2.69500000e+04, ...,\n",
       "            1.39639681e+18,   3.47970001e+02,   1.34429755e+18],\n",
       "         [  7.65000000e+02,   1.39853811e+18,   5.69780000e+04, ...,\n",
       "            1.39639681e+18,   3.47970001e+02,   1.34429755e+18],\n",
       "         [  7.65000000e+02,   1.39860752e+18,   2.01500000e+03, ...,\n",
       "            1.39639681e+18,   3.47970001e+02,   1.34429755e+18]],\n",
       " \n",
       "        ..., \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  5.82000000e+02,   1.38934798e+18,   5.76130000e+04, ...,\n",
       "            1.38913921e+18,   1.49121997e+03,   1.36762561e+18],\n",
       "         [  5.82000000e+02,   1.38936653e+18,   5.66200000e+03, ...,\n",
       "            1.38913921e+18,   1.49121997e+03,   1.36762561e+18],\n",
       "         [  5.82000000e+02,   1.38943773e+18,   5.01400000e+03, ...,\n",
       "            1.38913921e+18,   1.49121997e+03,   1.36762561e+18]],\n",
       " \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  5.82000000e+02,   1.39808140e+18,   2.19760000e+04, ...,\n",
       "            1.39700154e+18,   7.21359985e+02,   1.36762561e+18],\n",
       "         [  5.82000000e+02,   1.39809514e+18,   9.47700000e+03, ...,\n",
       "            1.39700154e+18,   7.21359985e+02,   1.36762561e+18],\n",
       "         [  5.82000000e+02,   1.39854251e+18,   4.82200000e+03, ...,\n",
       "            1.39700154e+18,   7.21359985e+02,   1.36762561e+18]],\n",
       " \n",
       "        [[ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         [ -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00, ...,\n",
       "           -1.00000000e+00,  -1.00000000e+00,  -1.00000000e+00],\n",
       "         ..., \n",
       "         [  1.82000000e+02,   1.38591145e+18,   4.64510000e+04, ...,\n",
       "            1.38551041e+18,   8.48099976e+01,   1.32287041e+18],\n",
       "         [  1.82000000e+02,   1.38969075e+18,   5.06420000e+04, ...,\n",
       "            1.38870724e+18,   3.56579987e+02,   1.32287041e+18],\n",
       "         [  1.82000000e+02,   1.39075453e+18,   2.64090000e+04, ...,\n",
       "            1.38870724e+18,   3.56579987e+02,   1.32287041e+18]]], dtype=float32),\n",
       " array([[[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        ..., \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 2.],\n",
       "         [ 2.],\n",
       "         ..., \n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]], dtype=float32))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.train_on_batch(self, x, y, sample_weight=None, class_weight=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
