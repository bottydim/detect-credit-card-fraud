{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!. ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "np.random.seed(1337)\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f function_to_profile statement_that_invokes_the_fuction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext cythonmagic => %load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "def sum_cythonized():\n",
    "    cdef long a = 0 # this directive defines a type for the variable\n",
    "    cdef int i = 0\n",
    "    for i in range(100000):\n",
    "        a += i\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_uncythonized():\n",
    "    a = 0\n",
    "    for i in range(100000):\n",
    "        a += i\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit sum_cythonized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit sum_uncythonized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_args(*types):\n",
    "    def real_decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for val, typ in zip(args, types):\n",
    "                assert isinstance(val, typ), \"Value {} is not of expected type {}\".format(val, typ)\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return real_decorator\n",
    "\n",
    "def do_long_computation(name):\n",
    "    \"\"\" dummy function \"\"\"\n",
    "    time.sleep(10)\n",
    "    return \"FruitMart\"\n",
    "\n",
    "@check_args(str, int, int)\n",
    "def print_fruit(name, apples, oranges):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "evt_name = 'Featurespace_events_output.csv'\n",
    "auth_name = 'Featurespace_auths_output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir+evt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pure = pd.read_csv(data_dir+auth_name,nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pure.TSYS_DCLN_REAS_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pure.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Nuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARD_VFCN_REJ_CD has only NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('acct_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_lbl = df.groupby('FRD_IND')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped_lbl.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var=grouped_lbl.count().stack()\n",
    "temp=var.unstack()\n",
    "type(temp)\n",
    "x_list = temp['acct_id']\n",
    "label_list = temp.index\n",
    "plt.axis(\"equal\") #The pie chart is oval by default. To make it a circle use pyplot.axis(\"equal\")\n",
    "#To show the percentage of each pie slice, pass an output format to the autopctparameter \n",
    "plt.pie(x_list,labels=label_list,autopct=\"%1.1f%%\") \n",
    "plt.title(\"Transactions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c,col in enumerate(col_names):\n",
    "    var=grouped_lbl.count().stack()\n",
    "    temp=var.unstack()\n",
    "    type(temp)\n",
    "    x_list = temp[col]\n",
    "    label_list = temp.index\n",
    "    plt.axis(\"equal\") #The pie chart is oval by default. To make it a circle use pyplot.axis(\"equal\")\n",
    "    #To show the percentage of each pie slice, pass an output format to the autopctparameter\n",
    "#     plt.subplot(12,4,c+1)\n",
    "    plt.pie(x_list,labels=label_list,autopct=\"%1.1f%%\") \n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "    if c==45:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def value_exist(val,col,df):\n",
    "    keys = set(df.groupby(col).groups.keys())\n",
    "    print keys\n",
    "    return val in keys\n",
    "col = 'AUTHZN_APPRL_CD'\n",
    "value_exist(55555,col,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = 55555\n",
    "df_rmna = df.fillna(value={'AUTHZN_APPRL_CD':val})\n",
    "df_rmna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_auth = pd.read_csv(data_dir+auth_name,nrows=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_auth[df_auth['MRCH_CITY_NM'].isnull() & df_auth['MRCH_NM']=='FYP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_auth['MRCH_NM'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_auth.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimated Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_seq = 1597.0\n",
    "epoch_t = 638\n",
    "time_per_seq = num_seq/epoch_t\n",
    "net_num_t = 2e6\n",
    "total_time = net_num_t*time_per_seq\n",
    "hours =total_time/3600\n",
    "days = hours/24\n",
    "print 'NET hours',hours\n",
    "print 'NET days',days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import datetime as dt\n",
    "from IPython.display import display\n",
    "\n",
    "import plotly.plotly as py # interactive graphing\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import Bar, Scatter, Marker, Layout, Figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "evt_name = 'Featurespace_events_output.csv'\n",
    "auth_name = 'Featurespace_auths_output.csv'\n",
    "db_name = 'c1_agg.db'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 if None else 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_sqlite3(dbname):\n",
    "    conn = sqlite3.connect(dbname)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_conn = init_sqlite3(data_dir+db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disk_engine = create_engine('sqlite:///'+data_dir+db_name,convert_unicode=True)\n",
    "disk_engine.raw_connection().connection.text_factory = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = 'auth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "df = pd.read_sql_query('select distinct FRD_IND,count(distinct acct_id) as num_usr '\n",
    "                       'from {table} '\n",
    "                       'group by FRD_IND'.format(table=table), disk_engine)\n",
    "t1 = time.time()\n",
    "print str(t1-t0)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "df = pd.read_sql_query('select distinct FRD_IND,count(distinct acct_id) as num_usr '\n",
    "                       'from {table} '\n",
    "                       'group by FRD_IND'.format(table=table), db_conn)\n",
    "t1 = time.time()\n",
    "print str(t1-t0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['num_usr'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = 'Fraud by Distinct Users'\n",
    "fig = {\n",
    "    'data': [{'labels': ['Fraud', 'Genuine'],\n",
    "              'values': [df['num_usr'][1], df['num_usr'][0]],\n",
    "              'type': 'pie'}],\n",
    "    'layout': {'title': title}\n",
    "     }\n",
    "iplot(fig,filename='figures/'+title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usr_ratio = df['num_usr'][0]/ df['num_usr'][1]\n",
    "usr_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usr_ratio= 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ds_u = pd.read_sql_query('select distinct acct_id, FRD_IND '\n",
    "                       'from {table} '\n",
    "                       'order by FRD_IND'.format(table=table), disk_engine)\n",
    "df_ds_u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_t_u = pd.read_sql_query('select acct_id, count(*) as num_trans '\n",
    "                       'from {table} '\n",
    "                        'group by acct_id '\n",
    "                        'order by -num_trans'.format(table=table), disk_engine)\n",
    "df_t_u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###graph bars %fraud al transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_val = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table= 'data_little'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_column(df_col):\n",
    "    print df_col.shape\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df_col)\n",
    "    return le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query('select * from {table}'.format(table=table),disk_engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "time_cols = ['AUTHZN_RQST_PROC_TM','PREV_ADR_CHNG_DT','PREV_PMT_DT','PREV_CARD_RQST_DT','FRD_IND_SWT_DT']\n",
    "for c,r in enumerate(df):\n",
    "    tp = df.dtypes[c]\n",
    "#     print tp\n",
    "    if tp == 'object':\n",
    "        if r not in time_cols:\n",
    "            encoders[r] = encode_column(df[r])\n",
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_encoders(table,disk_engine):\n",
    "    df = pd.read_sql_query('select * from {table}'.format(table=table),disk_engine)\n",
    "    cols = df.columns.values\n",
    "    encoders = {}\n",
    "    time_cols = ['AUTHZN_RQST_PROC_TM','PREV_ADR_CHNG_DT','PREV_PMT_DT','PREV_CARD_RQST_DT','FRD_IND_SWT_DT']\n",
    "    for c,r in enumerate(df):\n",
    "        tp = df.dtypes[c]\n",
    "    #     print tp\n",
    "        if tp == 'object':\n",
    "            if r not in time_cols:\n",
    "                encoders[r] = encode_column(df[r])\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def populate_encoders_scale(table,disk_engine):\n",
    "    df = pd.read_sql_query('select * from {table} limit 5'.format(table=table),disk_engine)\n",
    "    col_names = df.columns.values\n",
    "    encoders = {}\n",
    "    time_cols = ['AUTHZN_RQST_PROC_TM','PREV_ADR_CHNG_DT','PREV_PMT_DT','PREV_CARD_RQST_DT','FRD_IND_SWT_DT']\n",
    "    for c,name in enumerate(col_names):\n",
    "        tp = df.dtypes[c]\n",
    "    #     print tp\n",
    "        if tp == 'object':\n",
    "            if name not in time_cols:\n",
    "                df_col = pd.read_sql_query('select distinct {col_name} from {table}'.format(col_name=name,table=table),disk_engine)\n",
    "                encoders[name] = encode_column(np.array(df_col).ravel())\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = 'auth'\n",
    "encoders = populate_encoders_scale(table,disk_engine)\n",
    "# data_gen =  data_generator(disk_engine,encoders,table=table)\n",
    "# total_trans = 0\n",
    "# sample_num=484\n",
    "# while total_trans < sample_num:\n",
    "#     total_trains +=next(data_gen)[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = set()\n",
    "cnt = 0\n",
    "head = 0\n",
    "tail = len(df_ds_u.acct_id)-1\n",
    "sample_size = tail\n",
    "for i in range(sample_size):\n",
    "    \n",
    "    if cnt<usr_ratio:\n",
    "        users.add(df_ds_u.acct_id[head])\n",
    "        cnt+=1\n",
    "        head+=1\n",
    "    else:\n",
    "        users.add(df_ds_u.acct_id[tail])\n",
    "        tail-=1\n",
    "        cnt=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_df(df,encoders):\n",
    "    for col in encoders.keys():\n",
    "        try: \n",
    "            df[col] = encoders[col].transform(df[col])\n",
    "        except:\n",
    "            print 'EXCEPTION'\n",
    "            display(df[col])\n",
    "            print col \n",
    "            raise\n",
    "    for col in time_cols:\n",
    "        df[col] = pd.to_numeric(pd.to_datetime(df[col],errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_info(user,table):\n",
    "    if user == '.':\n",
    "        user = '\".\"'\n",
    "    df_u = pd.read_sql_query('select * from {table} where acct_id = {user}'.format(table=table,user=user),disk_engine)\n",
    "    return df_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_last_date(df_u,cuttoff_date):\n",
    "#     print \"Before Trim\"\n",
    "#     display(df_u)\n",
    "    df_trim = df_u[df_u['FRD_IND_SWT_DT'] >= pd.to_numeric(pd.Series(pd.to_datetime(cuttoff_date)))[0]]\n",
    "#     print \"After Trim\"\n",
    "#     display(df_trim)\n",
    "    ### a historicly later transaction may have been confirmed earlier than a historicly preceeding T\n",
    "    df_trim = df_trim.sort_values('AUTHZN_RQST_PROC_TM',ascending=True,inplace=False)\n",
    "    df_trim = df_trim.reset_index(drop=True)\n",
    "#     print \"After Reorder\"\n",
    "#     display(df_trim)\n",
    "#     display(df_trim)\n",
    "    if not df_trim.empty:\n",
    "#         print 'value to be returned',df_trim['AUTHZN_RQST_PROC_TM'][0]\n",
    "        return df_trim['AUTHZN_RQST_PROC_TM'][0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cuttoff_date='2014-05-11'\n",
    "pd.to_numeric(pd.Series(pd.to_datetime(cuttoff_date)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_col_id(col,df):\n",
    "    col_list = list(df.columns.values)\n",
    "    col_list.remove('index')\n",
    "    col_list.index(col)\n",
    "    \n",
    "def generate_sequence(user,table,encoders,cuttoff_date='2014-05-11'):\n",
    "    df_u = get_user_info(user,table)\n",
    "    unav_cols = ['AUTHZN_APPRL_CD','TSYS_DCLN_REAS_CD','AUTHZN_RESPNS_CD','AUTHZN_APPRD_AMT',]\n",
    "    nan_rpl = ['AUTHZN_APPRL_CD',]\n",
    "    for col in unav_cols:\n",
    "        df_u[col] = df_u[col].shift(1)\n",
    "        loc = list(df_u.columns.values).index(col)\n",
    "        if(col in nan_rpl):\n",
    "            df_u.iloc[0,loc] = 'nan'\n",
    "        else:\n",
    "            df_u.iloc[0,loc] = pad_val\n",
    "#     print df_u.count()\n",
    "#     display(df_u.head())\n",
    "#     display(df_u.sort_values('AUTHZN_RQST_PROC_TM',ascending=True))\n",
    "    encode_df(df_u,encoders)\n",
    "#     print df_u.count()\n",
    "#     display(df_u.head())\n",
    "#     display(df_u.sort_values('AUTHZN_RQST_PROC_TM',ascending=True))\n",
    "    df_u = df_u.sort_values('AUTHZN_RQST_PROC_TM',ascending=True)\n",
    "#     display(df_u[df_u['FRD_IND_SWT_DT'].isnull()])\n",
    "    df_u = df_u.drop('index', axis=1)\n",
    "#     display(df_u[df_u['FRD_IND_SWT_DT'] < pd.to_numeric(pd.Series(pd.to_datetime(cuttoff_date)))[0]].head(8))\n",
    "### This is the last date, before which transaction will be used for trainning. \n",
    "### It coresponds to the date when the last knwon fraudulent transaction was confirmed\n",
    "    last_date_num = get_last_date(df_u,cuttoff_date)\n",
    "    if last_date_num == None:\n",
    "        train = np.array(df_u)\n",
    "#         print \"No cutt offs\"\n",
    "#         print train[:,0:-2].shape\n",
    "#         print \"labels\"\n",
    "#         print train[:,-2].shape\n",
    "        return train[:,0:-2],[],train[:,-2],[]\n",
    "    else:\n",
    "        df_train = df_u[df_u['AUTHZN_RQST_PROC_TM'] < last_date_num]\n",
    "        df_test = df_u[df_u['AUTHZN_RQST_PROC_TM'] >= last_date_num]\n",
    "#     display(df_train)\n",
    "#     display(df_test)\n",
    "\n",
    "        \n",
    "    train = np.array(df_train)\n",
    "    test = np.array(df_test)\n",
    "\n",
    "#     print train\n",
    "#     print test\n",
    "#     print \"Shapes\"\n",
    "#     print train.shape\n",
    "#     print test.shape\n",
    "#     print \"features\"\n",
    "\n",
    "#     print train[:,0:-2].shape\n",
    "#     print test[:,0:-2].shape \n",
    "#     print \"labels\"\n",
    "#     print train[:,-2].shape\n",
    "#     print test[:,-2].shape \n",
    "    return train[:,0:-2],test[:,0:-2],train[:,-2],test[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user = '128237902'\n",
    "table = 'data_trim'\n",
    "encoders = encoders\n",
    "train,test,y,y_tes = generate_sequence(user,table,encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usr_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc = list(df.columns.values).index('AUTHZN_APPRL_CD')\n",
    "df.iloc[0,loc] = 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.TSYS_DCLN_REAS_CD.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[:,1] = np.roll(train[:,1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_roll_values(array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(col_list[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.array_split(X_train_S[0:2], 5)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map(lambda x: len(x),X_train_S[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split_seq = map(lambda x: np.array_split(x,math.ceil(len(x)/50.0)) if len(x)>50 else [x],X_train_S[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "172%50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map(lambda x: len(x),split_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(map(lambda x: reduce(lambda y,z: np.vstack([y,z]),x),split_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened = [sequence for user_seq in split_seq for sequence in user_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map(lambda x: len(x),flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunck_seq(seq_list,seq_len=50.0):\n",
    "    split_seq = map(lambda x: np.array_split(x,math.ceil(len(x)/seq_len)) if len(x)>seq_len else [x],seq_list)\n",
    "    flattened = [sequence for user_seq in split_seq for sequence in user_seq]\n",
    "    assert sum(map(lambda x: len(x),flattened)) == sum(map(lambda x: len(x),seq_list))\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pad_chunk = keras.preprocessing.sequence.pad_sequences(chunck_seq(X_train_S), maxlen=None,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pad_chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_pad = keras.preprocessing.sequence.pad_sequences(X_train_S, maxlen=None,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_S[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_pad[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sequence_generator(users,encoders,mode='train',table='data_trim',class_weight=None):\n",
    "    X_train_S = []\n",
    "    X_test_S = []\n",
    "    y_train_S =[]\n",
    "    y_test_S = []\n",
    "    print \"Number of users:\",len(users)\n",
    "    for user in users:\n",
    "    #     if user != '337018623': \n",
    "    #         continue\n",
    "        X_train,X_test,y_train,y_test = generate_sequence(user,table,encoders)\n",
    "        X_train_S.append(X_train)\n",
    "        X_test_S.append(X_test) \n",
    "        y_train_S.append(y_train)\n",
    "        y_test_S.append(y_test)\n",
    "    #     break\n",
    "    X_test_S = filter(lambda a: a != [], X_test_S)\n",
    "    y_test_S = filter(lambda a: a != [], y_test_S)\n",
    "    if mode =='train':\n",
    "        X_train_pad = keras.preprocessing.sequence.pad_sequences(chunck_seq(X_train_S), maxlen=None,dtype='float32',value=pad_val)\n",
    "        y_train_S = keras.preprocessing.sequence.pad_sequences(np.array(chunck_seq(y_train_S)), maxlen=None,dtype='float32',value=lbl_pad_val)\n",
    "        y_train_S = np.expand_dims(y_train_S, -1)\n",
    "        if class_weight != None:\n",
    "            shps = y_train_S.shape\n",
    "            sample_w = []\n",
    "            for i in range(shps[0]):\n",
    "                sample_w.append([])\n",
    "                for j in range(shps[1]):\n",
    "                    sample_w[i].append(class_weight[y_train_S[i,j,0]])\n",
    "            return X_train_pad,y_train_S,np.asarray(sample_w)\n",
    "#         print y_train_S\n",
    "#         print y_train_S.shape\n",
    "#         y_train_S = to_categorical(y_train_S,3)\n",
    "        return X_train_pad,y_train_S\n",
    "    else:\n",
    "        X_test_S_pad = keras.preprocessing.sequence.pad_sequences(chunck_seq(X_test_S), maxlen=None,dtype='float32',value=pad_val)\n",
    "        y_test_S = keras.preprocessing.sequence.pad_sequences(np.array(chunck_seq(y_test_S)),value=lbl_pad_val)\n",
    "        y_test_S = np.expand_dims(y_test_S, -1)\n",
    "        return X_test_S,y_test_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def user_generator(disk_engine,table='data_trim',sample_size=400,usr_ratio=80,mode='train'):\n",
    "    dataFrame = pd.read_sql_query('select distinct acct_id, FRD_IND,  '\n",
    "                       'from {table} '\n",
    "                       'order by FRD_IND'.format(table=table), disk_engine)\n",
    "#     display(dataFrame) \n",
    "    print \"User List acquired\"\n",
    "    u_list = list(dataFrame.acct_id)\n",
    "    print 'total # users:',len(u_list)\n",
    "    user_tr,user_ts = train_test_split(u_list, test_size=0.33, random_state=42)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        u_list =  user_tr\n",
    "    else:\n",
    "        u_list =  user_ts                              \n",
    "#     display(dataFrame.acct_id)\n",
    "    print 'return set cardinality:',len(u_list)\n",
    "    cnt = 0\n",
    "    head = 0\n",
    "    tail = len(u_list)-1\n",
    "    \n",
    "    while True:\n",
    "        users = set()\n",
    "        for i in range(sample_size):\n",
    "            \n",
    "            if cnt<usr_ratio:\n",
    "                users.add(u_list[head])\n",
    "                cnt+=1\n",
    "                head+=1\n",
    "            else:\n",
    "                users.add(u_list[tail])\n",
    "                tail-=1\n",
    "                cnt=0\n",
    "            if head ==tail:\n",
    "                    head = 0\n",
    "                    tail = len(u_list)-1\n",
    "#         print head\n",
    "#         print tail\n",
    "        print 'return list length:',len(users)\n",
    "        print '# users expiriencing both', len(u_list)-len(users)\n",
    "        yield users\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\",60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_gen = user_generator(disk_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(next(user_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(disk_engine,encoders,table='data_trim',sample_size=400,usr_ratio=80,class_weight=None):\n",
    "    user_gen = user_generator(disk_engine,usr_ratio=usr_ratio,sample_size=sample_size,table=table)\n",
    "    print \"Users generator\"\n",
    "    while True:\n",
    "        users = next(user_gen)\n",
    "        yield sequence_generator(users,encoders,mode='train',table=table,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_gen =  data_generator(disk_engine,encoders,table='data_trim',class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %debug\n",
    "X_train_pad,y_train_S,sample_w = next(data_gen)\n",
    "print X_train_pad.shape\n",
    "print y_train_S.shape\n",
    "print sample_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train_pad[-1]\n",
    "print y_train_S[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, LSTM, TimeDistributed, Masking\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_dim = 400\n",
    "num_layers = 1\n",
    "optimizer=keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-08)\n",
    "samples_per_epoch = 485\n",
    "nb_epoch = 20\n",
    "table = 'data_trim'\n",
    "lbl_pad_val = 2\n",
    "pad_val = -1\n",
    "class_weight = {0 : 1.,\n",
    "               1: 10.,\n",
    "               2: 0.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoders = populate_encoders(table,disk_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(50, 44),name='main_input')\n",
    "mask = Masking(mask_value=pad_val)(input_layer)\n",
    "prev = GRU(hidden_dim,#input_length=50,\n",
    "                  return_sequences=True,go_backwards=False,stateful=False,\n",
    "                  unroll=False,consume_less='gpu',\n",
    "                  init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "           inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "           b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(mask)\n",
    "# for i in range(num_layers-1):\n",
    "#     prev = GRU(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "#            inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "#            b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n",
    "output_layer = TimeDistributed(Dense(3,activation='softmax'))(prev)\n",
    "model = Model(input=[input_layer],output=[output_layer])\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy','hinge','squared_hinge','binary_accuracy','binary_crossentropy'])\n",
    "              metrics=['accuracy'],\n",
    "             sample_weight_mode=\"temporal\")\n",
    "data_gen =  data_generator(disk_engine,encoders,table=table,class_weight=class_weight)\n",
    "# data_gen =  data_generator(disk_engine,encoders,table=table,class_weight=class_weight)\n",
    "history = model.fit_generator(data_gen, samples_per_epoch, nb_epoch, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, class_weight=class_weight, max_q_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(X_train_pad.shape[0]):\n",
    "    if 1 in (list(y_train_S[i])):\n",
    "        print i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_ = 391\n",
    "join_= np.dstack([prediction,y_train_S])\n",
    "df_pred = pd.DataFrame(join_[id_])\n",
    "df_trim = df_pred.drop(df_pred[3]!=2.0)\n",
    "roc_join = np.array(df_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute ROC curve and area the curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(roc_join[:,3], roc_join[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = np.unique(roc_join[:,3])\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "join_= np.dstack([prediction,y_train_S])\n",
    "for i in range(prediction.shape[0]):\n",
    "    id_ = i \n",
    "\n",
    "    df_pred = pd.DataFrame(join_[id_])\n",
    "    display(df_pred)\n",
    "    df_trim = df_pred.drop(df_pred[df_pred.ix[:,3]==2.0].index)\n",
    "    display(df_trim)\n",
    "    roc_join = np.array(df_trim)\n",
    "    \n",
    "    classes = np.unique(roc_join[:,3])\n",
    "    print classes\n",
    "    fpr, tpr, thresholds = roc_curve(roc_join[:,3], roc_join[:,1])\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
    "         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = 23\n",
    "d = {'target' : pd.Series(np.reshape(y_train_S[index],len(y_train_S[index]))),\n",
    "    'pred' : pd.Series(np.reshape(prediction[index][0],len(prediction[index][0]))),\n",
    "    'pred_2' : pd.Series(np.reshape(prediction[index][1],len(prediction[index][1]))),}\n",
    "df_pred = pd.DataFrame(d)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hid_dim = [256,512,1024,2048]\n",
    "num_l = [1,2,3,4,5,6,7,8,9,10]\n",
    "lr_s = [1e-1,1e-2,1e-3]\n",
    "opts = lambda x,lr:[keras.optimizers.RMSprop(lr=lr, rho=0.9, epsilon=1e-08),\n",
    "                keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "                   keras.optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)][x] \n",
    "hidden_dim = 400\n",
    "num_layers = 1\n",
    "optimizer=keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-08)\n",
    "samples_per_epoch = 485\n",
    "nb_epoch = 20\n",
    "table = 'data_trim'\n",
    "lbl_pad_val = 2\n",
    "pad_val = -1\n",
    "encoders = populate_encoders(table,disk_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opts(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for hidden_dim in hid_dim:\n",
    "    for opt_id in range(3):\n",
    "        for lr in lr_s:\n",
    "            optimizer = opts(opt_id,lr)\n",
    "            for num_layers in num_l:\n",
    "                for rnn in ['gru','lstm']\n",
    "                    input_layer = Input(shape=(50, 44),name='main_input')\n",
    "                    mask = Masking(mask_value=0)(input_layer)\n",
    "                    if rnn == gru:\n",
    "                    prev = GRU(hidden_dim,#input_length=50,\n",
    "                                      return_sequences=True,go_backwards=False,stateful=False,\n",
    "                                      unroll=False,consume_less='gpu',\n",
    "                                      init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "                               inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "                               b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(mask)\n",
    "                    for i in range(num_layers-1):\n",
    "                        prev = GRU(hidden_dim,#input_length=50,\n",
    "                                      return_sequences=True,go_backwards=False,stateful=False,\n",
    "                                      unroll=False,consume_less='gpu',\n",
    "                                      init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "                               inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "                               b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(prev)\n",
    "                    output_layer = TimeDistributed(Dense(1))(prev)\n",
    "                    model = Model(input=[input_layer],output=[output_layer])\n",
    "                    model.compile(optimizer=optimizer,\n",
    "                                  loss='binary_crossentropy',\n",
    "                                  metrics=['accuracy'])\n",
    "                    data_gen =  data_generator(disk_engine,encoders,table=table)\n",
    "                    history = model.fit_generator(data_gen, samples_per_epoch, nb_epoch, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(data_gen, samples_per_epoch, nb_epoch, verbose=1, callbacks=[],validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print train_test_split(range(10), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print len(X_train_S)\n",
    "print len(X_test_S)\n",
    "print len(y_train_S)\n",
    "print len(y_test_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'.' in users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query('select * '\n",
    "                       'from {table} '.format(table=table), disk_engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df.MRCH_NM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoders['acct_id'].transform(['.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_u = get_user_info(\"'.'\",'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_u= df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_u[df_u['FRD_IND']=='Y'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Timestamp('20120101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_u[df_u['FRD_IND_SWT_DT']>pd.Timestamp('20120101')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_u['AUTHZN_AMT']>10\n",
    "df_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_u[df_u['FRD_IND']=='Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_u['FRD_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_u[df_u['acct_id']=='337018623']['CAVV_CD'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Timestamp('2013-05-11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df_u[df_u['acct_id']=='337018623']['CAVV_CD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le.transform([None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.to_numeric(pd.Series(pd.to_datetime('2013-05-11')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_numeric(pd.Series(pd.to_datetime('2014-05-11')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(10.0)\n",
    "np.array_split(x, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a simple chart..\n",
    "trace = Scatter(x=history.epoch,y=history.history['acc'])\n",
    "data = [trace]\n",
    "layout = Layout(title=title, width=800, height=640)\n",
    "fig = Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\ttitle = 'Training Acc'\n",
    "\tfig = {\n",
    "    \t'data': [Scatter(\n",
    "    \t\tx=history.epoch,\n",
    "    \t\ty=history.history['acc'])],\n",
    "    \t'layout': {'title': title}\n",
    "     \t}\n",
    "# \tiplot(fig,filename='figures/'+title)\n",
    "# \tiplot(fig,filename='figures/'+title,image='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    gru_dict = {}\n",
    "    lstm_dict = {}\n",
    "    for hidden_dim in hid_dim:\n",
    "      gru_dict[hidden_dim] = {}\n",
    "      lstm_dict[hidden_dim] = {}\n",
    "      for opt_id in range(3):\n",
    "          for lr in lr_s:\n",
    "              optimizer = opts(opt_id,lr)\n",
    "              gru_dict[hidden_dim][type(optimizer).__name__] = {}\n",
    "              lstm_dict[hidden_dim][type(optimizer).__name__] = {}\n",
    "              for num_layers in num_l:\n",
    "                  for rnn in ['gru','lstm']\n",
    "                      input_layer = Input(shape=(50, 44),name='main_input')\n",
    "                      mask = Masking(mask_value=0)(input_layer)\n",
    "                      if rnn == gru:\n",
    "                          prev = GRU(hidden_dim,#input_length=50,\n",
    "                                              return_sequences=True,go_backwards=False,stateful=False,\n",
    "                                              unroll=False,consume_less='gpu',\n",
    "                                              init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "                                      inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "                                      b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(mask)\n",
    "                        else:\n",
    "                          prev = LSTM(hidden_dim, init='glorot_uniform', inner_init='orthogonal', \n",
    "                              forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid',\n",
    "                               W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(prev)\n",
    "                      for i in range(num_layers-1):\n",
    "                          if rnn == gru:\n",
    "                              prev = GRU(hidden_dim,#input_length=50,\n",
    "                                                  return_sequences=True,go_backwards=False,stateful=False,\n",
    "                                                  unroll=False,consume_less='gpu',\n",
    "                                                  init='glorot_uniform', inner_init='orthogonal', activation='tanh',\n",
    "                                          inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None,\n",
    "                                          b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(prev)\n",
    "                          else:\n",
    "                              prev = LSTM(hidden_dim, init='glorot_uniform', inner_init='orthogonal', \n",
    "                                  forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid',\n",
    "                                  W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)(prev)\n",
    "                      output_layer = TimeDistributed(Dense(1))(prev)\n",
    "                      \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = title.replace('Loss','Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gru_ = {}\n",
    "gru_[5] = {}\n",
    "gru_[5][1] = 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(optimizer).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine import generator_queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zs = np.zeros([100])\n",
    "zs = zs + np.arange(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zs[np.where(zs>65)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoders['FRD_IND'].inverse_transform([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ccfd_dnn.model import *\n",
    "gen = eval_generator('train','test',disk_engine,encoders,table='data_trim',\n",
    "                   sample_size=400,usr_ratio=80,class_weight=None,lbl_pad_val = 2, pad_val = -1)\n",
    "\n",
    "gen = eval_trans_generator(disk_engine,encoders,table='data_trim',sample_size=400,usr_ratio=80,class_weight=None,lbl_pad_val = 2, pad_val = -1)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.array([])\n",
    "if arr.size ==0:\n",
    "    print 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
