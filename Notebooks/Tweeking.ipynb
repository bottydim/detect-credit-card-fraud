{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "import sqlite3\n",
    "import time\n",
    "import numpy as np\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine # database connection\n",
    "from sqlalchemy import Index\n",
    "import datetime as dt\n",
    "from IPython.display import display\n",
    "from sklearn import preprocessing\n",
    "import plotly.plotly as py # interactive graphing\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import Bar, Scatter, Marker, Layout, Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "evt_name = 'Featurespace_events_output.csv'\n",
    "auth_name = 'Featurespace_auths_output.csv'\n",
    "db_name = 'c1_agg.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disk_engine = create_engine('sqlite:///'+data_dir+db_name,convert_unicode=True)\n",
    "disk_engine.raw_connection().connection.text_factory = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = 'data_more'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.33954715729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object _query_iterator at 0x7f66d435ca50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "df = pd.read_sql_query('select distinct FRD_IND,count(distinct acct_id) as num_usr '\n",
    "                       'from {table} '\n",
    "                       'group by FRD_IND'.format(table=table), disk_engine,chunksize=1000)\n",
    "t1 = time.time()\n",
    "print str(t1-t0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_column(df_col):\n",
    "    print df_col.shape\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df_col)\n",
    "    return le\n",
    "def populate_encoders_scale(table,disk_engine):\n",
    "    df = pd.read_sql_query('select * from {table} limit 5'.format(table=table),disk_engine)\n",
    "    col_names = df.columns.values\n",
    "    encoders = {}\n",
    "    time_cols = ['AUTHZN_RQST_PROC_TM','PREV_ADR_CHNG_DT','PREV_PMT_DT','PREV_CARD_RQST_DT','FRD_IND_SWT_DT']\n",
    "    for c,name in enumerate(col_names):\n",
    "        tp = df.dtypes[c]\n",
    "    #     print tp\n",
    "\n",
    "        if tp == 'object':\n",
    "            if name not in time_cols:\n",
    "                print name\n",
    "                df_cols = pd.read_sql_query('select distinct {col_name} from {table}'.format(col_name=name,table=table),disk_engine,chunksize=100000)\n",
    "                arr = np.array(0)\n",
    "                progress = progressbar.ProgressBar(widgets=[progressbar.Bar('=', '[', ']'), ' ',\n",
    "                                            progressbar.Percentage(), ' ',\n",
    "                                            progressbar.ETA()]).start()\n",
    "                for c,df_col in enumerate(df_cols): \n",
    "                    arr = np.vstack((arr,np.array(df_col)))\n",
    "                    progress.update(c+1)\n",
    "                progress.finish()\n",
    "                encoders[name] = encode_column(np.array(arr).ravel())\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "address = \"postgresql+pg8000://script@localhost:5432/ccfd\"\n",
    "engine = create_engine(address)\n",
    "connection = engine.raw_connection()\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'index', u'acct_id', u'AUTHZN_RQST_PROC_TM', u'AUTHZN_APPRL_CD',\n",
       "       u'AUTHZN_AMT', u'MRCH_NM', u'MRCH_CITY_NM', u'MRCH_PSTL_CD',\n",
       "       u'MRCH_CNTRY_CD', u'MRCH_ID', u'TRMNL_ID', u'MRCH_CATG_CD',\n",
       "       u'POS_ENTRY_MTHD_CD', u'POS_COND_CD', u'TRMNL_CLASFN_CD',\n",
       "       u'TRMNL_CAPBLT_CD', u'TRMNL_PIN_CAPBLT_CD', u'TSYS_DCLN_REAS_CD',\n",
       "       u'MRCH_TMP_PRTPN_IND', u'AUTHZN_MSG_TYPE_MODR_CD',\n",
       "       u'AUTHZN_ACCT_STAT_CD', u'AUTHZN_MSG_TYPE_CD',\n",
       "       u'AUTHZN_RQST_TYPE_CD', u'AUTHZN_RESPNS_CD', u'ACCT_STAT_REAS_NUM',\n",
       "       u'RQST_CARD_SEQ_NUM', u'PIN_OFST_IND', u'PIN_VLDTN_IND',\n",
       "       u'CARD_VFCN_REJ_CD', u'CARD_VFCN_RESPNS_CD',\n",
       "       u'CARD_VFCN2_RESPNS_CD', u'CAVV_CD', u'ECMRC_SCURT_CD',\n",
       "       u'ACQR_BIN_NUM', u'ACQR_CRCY_CD', u'CRCY_CNVRSN_RT',\n",
       "       u'AUTHZN_APPRD_AMT', u'PRIOR_MONEY_AVL_AMT', u'PRIOR_CASH_AVL_AMT',\n",
       "       u'ACCT_CL_AMT', u'ACCT_CURR_BAL', u'PREV_ADR_CHNG_DT',\n",
       "       u'PREV_PMT_DT', u'PREV_PMT_AMT', u'PREV_CARD_RQST_DT', u'FRD_IND',\n",
       "       u'FRD_IND_SWT_DT'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = 'event'\n",
    "df = pd.read_sql_query('select * from {table} limit 5'.format(table=table),engine)\n",
    "col_names = df.columns.values\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) database is locked [SQL: 'CREATE INDEX id_acct_id                     ON data_more (acct_id)']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-a4fd1fbf82d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CREATE INDEX id_{col}                     ON {table} ({col})'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, object, *multiparams, **params)\u001b[0m\n\u001b[0;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m    905\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 906\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    907\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_text\u001b[1;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[0;32m   1052\u001b[0m             \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m             \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m         )\n\u001b[0;32m   1056\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m                 context)\n\u001b[0m\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   1339\u001b[0m                 util.raise_from_cause(\n\u001b[0;32m   1340\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m                     \u001b[0mexc_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m                 )\n\u001b[0;32m   1343\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sqlalchemy/util/compat.pyc\u001b[0m in \u001b[0;36mraise_from_cause\u001b[1;34m(exception, exc_info)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[0mcause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpy3k\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m                         \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m                         \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m                         context)\n\u001b[0m\u001b[0;32m   1140\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             self._handle_dbapi_exception(\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sqlalchemy/engine/default.pyc\u001b[0m in \u001b[0;36mdo_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) database is locked [SQL: 'CREATE INDEX id_acct_id                     ON data_more (acct_id)']"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql_query('select * from {table} limit 5'.format(table=table),disk_engine)\n",
    "col_names = df.columns.values\n",
    "with disk_engine.connect() as conn:\n",
    "    for c,name in enumerate(col_names):\n",
    "        if name =='index':\n",
    "            continue\n",
    "        conn.execute('CREATE INDEX id_{col} \\\n",
    "                    ON {table} ({col})'.format(table=table,col=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acct_id\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'classobj'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-04165e732e3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpopulate_encoders_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisk_engine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-85a75a18c041>\u001b[0m in \u001b[0;36mpopulate_encoders_scale\u001b[1;34m(table, disk_engine)\u001b[0m\n\u001b[0;32m     21\u001b[0m                                             \u001b[0mprogressbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPercentage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                                             progressbar.ETA()])\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mdf_col\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#                     progress.update(c+1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/progressbar/__init__.pyc\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrval\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/progressbar/__init__.pyc\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_update_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/progressbar/__init__.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseconds_elapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnow\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_update\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrval\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_update_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/progressbar/__init__.pyc\u001b[0m in \u001b[0;36m_format_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;34m'Joins the widgets and justifies the line'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[0mwidgets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_widgets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_justify\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterm_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/progressbar/__init__.pyc\u001b[0m in \u001b[0;36m_format_widgets\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[0mexpanding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[0mwidget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_updatable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[0mwidth\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/progressbar/widgets.pyc\u001b[0m in \u001b[0;36mformat_updatable\u001b[1;34m(updatable, pbar)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mformat_updatable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdatable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdatable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'update'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mupdatable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mupdatable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/progressbar/widgets.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, pbar)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'%3d%%'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/progressbar/__init__.pyc\u001b[0m in \u001b[0;36mpercentage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpercentage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m'Returns the progress as a percentage.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrval\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[0mpercent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproperty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'classobj'"
     ]
    }
   ],
   "source": [
    "populate_encoders_scale(table,disk_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, cuDNN 5103)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py:600: UserWarning:\n",
      "\n",
      "Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score,classification_report\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import datetime as dt\n",
    "import io\n",
    "\n",
    "import plotly.plotly as py # interactive graphing\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import Bar, Scatter, Marker, Layout, Figure\n",
    "from heraspy.model import HeraModel\n",
    "np.random.seed(1337)\n",
    "import theano\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, LSTM, TimeDistributed, Masking\n",
    "from keras.engine.training import *\n",
    "from IPython.display import display\n",
    "\n",
    "time_cols = ['AUTHZN_RQST_PROC_TM','PREV_ADR_CHNG_DT','PREV_PMT_DT','PREV_CARD_RQST_DT','FRD_IND_SWT_DT']\n",
    "seq_len_param = 60.0\n",
    "def encode_column(df_col):\n",
    "    print df_col.shape\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df_col)\n",
    "    return le\n",
    "\n",
    "def populate_encoders(table,disk_engine):\n",
    "    df = pd.read_sql_query('select * from {table}'.format(table=table),disk_engine)\n",
    "    df.head()\n",
    "    encoders = {}\n",
    "    for c,r in enumerate(df):\n",
    "        tp = df.dtypes[c]\n",
    "    #     print tp\n",
    "        if tp == 'object':\n",
    "            if r not in time_cols:\n",
    "                encoders[r] = encode_column(df[r])\n",
    "    return encoders\n",
    "\n",
    "def populate_encoders_scale(table,disk_engine):\n",
    "    df = pd.read_sql_query('select * from {table} limit 5'.format(table=table),disk_engine)\n",
    "    col_names = df.columns.values\n",
    "    encoders = {}\n",
    "    time_cols = ['AUTHZN_RQST_PROC_TM','PREV_ADR_CHNG_DT','PREV_PMT_DT','PREV_CARD_RQST_DT','FRD_IND_SWT_DT']\n",
    "    for c,name in enumerate(col_names):\n",
    "        tp = df.dtypes[c]\n",
    "    #     print tp\n",
    "\n",
    "        if tp == 'object':\n",
    "            if name not in time_cols:\n",
    "                print name\n",
    "                df_cols = pd.read_sql_query('select distinct {col_name} from {table}'.format(col_name=name,table=table),disk_engine,chunksize=100000)\n",
    "                arr = np.array(0)\n",
    "                progress = progressbar.ProgressBar(widgets=[progressbar.Bar('=', '[', ']'), ' ',\n",
    "                                            progressbar.Percentage(), ' ',\n",
    "                                            progressbar.ETA()]).start()\n",
    "                for c,df_col in enumerate(df_cols): \n",
    "                    arr = np.vstack((arr,np.array(df_col)))\n",
    "                    progress.update(c+1)\n",
    "                progress.finish()\n",
    "                encoders[name] = encode_column(np.array(arr).ravel())\n",
    "    return encoders\n",
    "\n",
    "def encode_df(df,encoders):\n",
    "    for col in encoders.keys():\n",
    "        try: \n",
    "            df[col] = encoders[col].transform(df[col])\n",
    "        except:\n",
    "            print 'EXCEPTION'\n",
    "            print col \n",
    "            raise\n",
    "    for col in time_cols:\n",
    "        df[col] = pd.to_numeric(pd.to_datetime(df[col],errors='coerce'))\n",
    "\n",
    "\n",
    "def get_user_info(user,table,disk_engine):\n",
    "    if user == '.':\n",
    "        user = '\".\"'\n",
    "    df_u = pd.read_sql_query('select * from {table} where acct_id = {user}'.format(table=table,user=user),disk_engine)\n",
    "    return df_u\n",
    "\n",
    "def get_last_date(cutt_off_date,table,disk_engine):\n",
    "    query = ['select AUTHZN_RQST_PROC_TM '\n",
    "    'from {table} '\n",
    "    'where FRD_IND_SWT_DT >=' \n",
    "         '\"',\n",
    "    cutt_off_date,\n",
    "         '\" '\n",
    "    'order by AUTHZN_RQST_PROC_TM limit 1 '\n",
    "    ]\n",
    "    query = ''.join(query)\n",
    "    query = query.format(table=table)\n",
    "    dataFrame = pd.read_sql_query(query\n",
    "                       .format(table=table), disk_engine)\n",
    "    print pd.to_numeric(pd.to_datetime(dataFrame['AUTHZN_RQST_PROC_TM']))\n",
    "    return pd.to_numeric(pd.to_datetime(dataFrame['AUTHZN_RQST_PROC_TM']))[0]\n",
    "\n",
    "def get_col_id(col,df):\n",
    "    col_list = list(df.columns.values)\n",
    "    col_list.remove('index')\n",
    "    col_list.index(col)\n",
    "    \n",
    "def generate_sequence(user,table,encoders,disk_engine,lbl_pad_val,pad_val,last_date):\n",
    "    df_u = get_user_info(user,table,disk_engine)\n",
    "    unav_cols = ['AUTHZN_APPRL_CD','TSYS_DCLN_REAS_CD','AUTHZN_RESPNS_CD','AUTHZN_APPRD_AMT',]\n",
    "    nan_rpl = ['AUTHZN_APPRL_CD',]\n",
    "    for col in unav_cols:\n",
    "        df_u[col] = df_u[col].shift(1)\n",
    "        loc = list(df_u.columns.values).index(col)\n",
    "        if(col in nan_rpl):\n",
    "            df_u.iloc[0,loc] = 'nan'\n",
    "        else:\n",
    "            df_u.iloc[0,loc] = pad_val\n",
    "#     print df_u.count()\n",
    "#     display(df_u.head())\n",
    "#     display(df_u.sort_values('AUTHZN_RQST_PROC_TM',ascending=True))\n",
    "    encode_df(df_u,encoders)\n",
    "#     print df_u.count()\n",
    "#     display(df_u.head())\n",
    "#     display(df_u.sort_values('AUTHZN_RQST_PROC_TM',ascending=True))\n",
    "    df_u = df_u.sort_values('AUTHZN_RQST_PROC_TM',ascending=True)\n",
    "#     display(df_u[df_u['FRD_IND_SWT_DT'].isnull()])\n",
    "    df_u = df_u.drop('index', axis=1)\n",
    "#     display(df_u[df_u['FRD_IND_SWT_DT'] < pd.to_numeric(pd.Series(pd.to_datetime(cuttoff_date)))[0]].head(8))\n",
    "### This is the last date, before which transaction will be used for trainning. \n",
    "### It coresponds to the date when the last knwon fraudulent transaction was confirmed\n",
    "    last_date_num = last_date\n",
    "\n",
    "    df_train = df_u[df_u['AUTHZN_RQST_PROC_TM'] < last_date_num]\n",
    "    # display(df_train.head())\n",
    "    df_test = df_u[df_u['AUTHZN_RQST_PROC_TM'] >= last_date_num]\n",
    "    # display(df_test.head())\n",
    "    train = np.array(df_train)\n",
    "    test = np.array(df_test)\n",
    "    if df_train.empty:\n",
    "        return [],test[:,0:-2],[],test[:,-2]\n",
    "    if df_test.empty:\n",
    "        # print 'train/test sequence split:',np.array(df_train).shape[0],np.array(df_test).shape[0]\n",
    "        return train[:,0:-2],[],train[:,-2],[]\n",
    "#     display(df_train)\n",
    "#     display(df_test)\n",
    "\n",
    "        \n",
    "\n",
    "    # print 'test shape in sequencer',test.shape\n",
    "    return train[:,0:-2],test[:,0:-2],train[:,-2],test[:,-2]\n",
    "\n",
    "def chunck_seq(seq_list,seq_len=seq_len_param):\n",
    "    split_seq = map(lambda x: np.array_split(x,math.ceil(len(x)/seq_len)) if len(x)>seq_len else [x],seq_list)\n",
    "    flattened = [sequence for user_seq in split_seq for sequence in user_seq]\n",
    "    assert sum(map(lambda x: len(x),flattened)) == sum(map(lambda x: len(x),seq_list))\n",
    "    chunks_lens = map(lambda x: len(x),flattened)\n",
    "    for cnk in chunks_lens:\n",
    "        assert cnk <= seq_len_param, 'Sequence chunks are exceeding the max_len of {} \\n {}'.format(seq_len_param,chunks_lens)\n",
    "    return flattened\n",
    "\n",
    "def generate_sample_w(y_true,class_weight):\n",
    "    shps = y_true.shape\n",
    "    sample_w = []\n",
    "    for i in range(shps[0]):\n",
    "        sample_w.append([])\n",
    "        for j in range(shps[1]):\n",
    "            sample_w[i].append(class_weight[y_true[i,j,0]])\n",
    "    return np.asarray(sample_w)\n",
    "def sequence_generator(users,encoders,disk_engine,lbl_pad_val,pad_val,last_date,mode='train',table='data_trim',class_weight=None,):\n",
    "    X_train_S = []\n",
    "    X_test_S = []\n",
    "    y_train_S =[]\n",
    "    y_test_S = []\n",
    "    print \"Number of users:\",len(users)\n",
    "    for user in users:\n",
    "    #     if user != '337018623': \n",
    "    #         continue\n",
    "        X_train,X_test,y_train,y_test = generate_sequence(user,table,encoders,disk_engine,lbl_pad_val,pad_val,last_date)\n",
    "        if type(X_train) != list:\n",
    "            assert X_train.shape[0] == y_train.shape[0], 'Sequence mismatch for user {user}: X_Train.shape {x_shape}'\\\n",
    "                    ' : y_train.shape {y_shape} \\n'.format(user=user,x_shape=X_train.shape,y_shape=y_train.shape)\n",
    "\n",
    "        # print 'shapes:',X_train.shape[0],\":\",y_train.shape[0]\n",
    "        # if X_test != []:\n",
    "        #     print 'shape in generator',X_test.shape\n",
    "        X_train_S.append(X_train)\n",
    "        X_test_S.append(X_test) \n",
    "        y_train_S.append(y_train)\n",
    "        y_test_S.append(y_test)\n",
    "    #     break\n",
    "\n",
    "\n",
    "    X_train_S = filter(lambda a: len(a) != 0, X_train_S)\n",
    "    y_train_S = filter(lambda a: len(a) != 0, y_train_S)\n",
    "    X_test_S = filter(lambda a: len(a) != 0, X_test_S)\n",
    "    y_test_S = filter(lambda a: len(a) != 0, y_test_S)\n",
    "\n",
    "\n",
    "\n",
    "    if mode =='train':\n",
    "        # chuncked = chunck_seq(X_train_S)\n",
    "        # assert \n",
    "        X_train_pad = keras.preprocessing.sequence.pad_sequences(chunck_seq(X_train_S), maxlen=int(seq_len_param),dtype='float32',value=pad_val)\n",
    "        y_train_S = keras.preprocessing.sequence.pad_sequences(np.array(chunck_seq(y_train_S)), maxlen=int(seq_len_param),dtype='float32',value=lbl_pad_val)\n",
    "        y_train_S = np.expand_dims(y_train_S, -1)\n",
    "        # print 'xs shape',X_train_pad.shape\n",
    "        # print 'labels shape',y_train_S.shape\n",
    "        if class_weight != None:\n",
    "\n",
    "            sample_w = generate_sample_w(y_train_S,class_weight)\n",
    "            return X_train_pad,y_train_S,sample_w\n",
    "#         print y_train_S\n",
    "#         print y_train_S.shape\n",
    "#         y_train_S = to_categorical(y_train_S,3)\n",
    "        return X_train_pad,y_train_S\n",
    "    else:\n",
    "        X_test_S_pad = keras.preprocessing.sequence.pad_sequences(chunck_seq(X_test_S), maxlen=int(seq_len_param),dtype='float32',value=pad_val)\n",
    "        y_test_S = keras.preprocessing.sequence.pad_sequences(np.array(chunck_seq(y_test_S)),maxlen=int(seq_len_param),dtype='float32',value=lbl_pad_val)\n",
    "        y_test_S = np.expand_dims(y_test_S, -1)\n",
    "        print 'labels shape',y_test_S.shape\n",
    "        if class_weight != None:\n",
    "            sample_w = generate_sample_w(y_test_S,class_weight)\n",
    "            return X_test_S_pad,y_test_S,sample_w\n",
    "        return X_test_S_pad,y_test_S\n",
    "\n",
    "\n",
    "def get_count_table(table,disk_engine,cutt_off_date,trans_mode):\n",
    "    query = ['select acct_id,count(*) '\n",
    "        'as num_trans from {table} '\n",
    "        'where AUTHZN_RQST_PROC_TM <= '\n",
    "        '(select AUTHZN_RQST_PROC_TM '\n",
    "        'from {table} '\n",
    "        'where FRD_IND_SWT_DT >=' \n",
    "             '\"',\n",
    "        cutt_off_date,\n",
    "             '\" '\n",
    "        'order by AUTHZN_RQST_PROC_TM limit 1) '\n",
    "        'group by acct_id order by num_trans']\n",
    "    query = ''.join(query)\n",
    "    query = query.format(table=table)\n",
    "    if trans_mode == 'test':\n",
    "        query = query.replace('<=','>')\n",
    "    dataFrame = pd.read_sql_query(query\n",
    "                       .format(table=table), disk_engine)\n",
    "    return dataFrame\n",
    "\n",
    "def trans_num_table(table,disk_engine,mode='train',cutt_off_date='2014-05-11',trans_mode='train'):\n",
    "\n",
    "    dataFrame = get_count_table(table,disk_engine,cutt_off_date,trans_mode)\n",
    "    u_list = set(dataFrame.acct_id)\n",
    "    \n",
    "    user_tr,user_ts = train_test_split(list(u_list), test_size=0.33, random_state=42)\n",
    "\n",
    "    total_t =0\n",
    "    if mode == 'train':\n",
    "        users = user_tr\n",
    "    else:\n",
    "        users = user_ts\n",
    "    \n",
    "    total_t = total_trans_batch(users,dataFrame)\n",
    "    return math.ceil(total_t)\n",
    "\n",
    "\n",
    "def total_trans_batch(users,dataFrame_count):\n",
    "    num_trans = 0\n",
    "    users = set(users)\n",
    "    for user in users:\n",
    "        num_trans+=get_num_trans(user,dataFrame_count)\n",
    "    return num_trans\n",
    "\n",
    "def get_num_trans(user,dfc):\n",
    "    try:\n",
    "        df = dfc[dfc['acct_id']==user]\n",
    "        if df.empty:\n",
    "            print \" user not existing in the table\",user\n",
    "            seq_len = 0\n",
    "        else:\n",
    "            seq_len = dfc[dfc['acct_id']==user].values[0][1]\n",
    "    except:\n",
    "        print dfc[dfc['acct_id']==user]\n",
    "        raise\n",
    "    return math.ceil(1.0*seq_len/seq_len_param)\n",
    "\n",
    "def add_user(index,u_list,dataFrame_count,users):\n",
    "    cnt_trans = 0\n",
    "    user = u_list[index]\n",
    "    if user not in users:\n",
    "        users.add(user)\n",
    "        return get_num_trans(user,dataFrame_count)\n",
    "    else:\n",
    "        return 0\n",
    "def user_generator(disk_engine,table='data_trim',batch_size=50,usr_ratio=80,\n",
    "                   mode='train',cutt_off_date='2014-05-11',trans_mode='train',sub_sample=None):\n",
    "\n",
    "\n",
    "    dataFrame_count = get_count_table(table,disk_engine,cutt_off_date,trans_mode)\n",
    "    \n",
    "#     display(dataFrame_count.head(5)) \n",
    "    print \"User List acquired\"\n",
    "    u_list = list(dataFrame_count.acct_id)\n",
    "#     u_list.extend(list(dataFrame_Y.acct_id))\n",
    "    print 'total # users:',len(u_list)\n",
    "    u_set = set(u_list)\n",
    "    print 'total # unique users:',len(u_set) \n",
    "    user_tr,user_ts = train_test_split(list(u_set), test_size=0.33, random_state=42)\n",
    "    print 'total # sequences:',total_trans_batch(list(u_set),dataFrame_count)\n",
    "    if mode == 'train':\n",
    "        u_list =  user_tr\n",
    "    else:\n",
    "        u_list =  user_ts\n",
    "    if trans_mode == 'test':\n",
    "        print 'used # sequences: value is inaccurate, please implement'\n",
    "    print 'used # sequences:',total_trans_batch(u_list,dataFrame_count)                         \n",
    "#     display(dataFrame.acct_id)\n",
    "    \n",
    "    u_list = list(set(u_list))\n",
    "    print 'return set cardinality:',len(u_list)\n",
    "    cnt = 0\n",
    "    head = 0\n",
    "    tail = len(u_list)-1\n",
    "    u_list_all = u_list\n",
    "    batch_size_temp = batch_size\n",
    "    to_be_used = batch_size\n",
    "    while True:\n",
    "        total_sequences = 0\n",
    "        users = set()\n",
    "        cnt_trans = 0\n",
    "        if sub_sample != None:\n",
    "            assert sub_sample<=len(u_list_all), 'sub_sample size select is {sub_sample}, but there are only {us} users'.format(sub_sample=sub_sample,us=len(u_list_all))\n",
    "            u_list = np.random.choice(u_list_all, sub_sample,replace=False)\n",
    "            print 'indeed they have been generated'\n",
    "            ### reset tail value, to avoid outof bounds exception\n",
    "            tail = len(u_list)-1\n",
    "            #####if using subsample the batch should be no larger than the total number of sequences\n",
    "            to_be_used = total_trans_batch(u_list,dataFrame_count)  \n",
    "            print 'batch_size: {bs} : to_be_used {tbu} : user_sub_sample {usr}'.format(bs=batch_size,tbu=to_be_used,usr=len(u_list))\n",
    "            \n",
    "            if batch_size_temp > to_be_used:\n",
    "                batch_size = to_be_used\n",
    "            else:\n",
    "                batch_size = batch_size_temp\n",
    "        while total_sequences < to_be_used:\n",
    "            while cnt_trans<batch_size:\n",
    "                \n",
    "                if cnt<usr_ratio:\n",
    "                    cnt_trans+=add_user(head,u_list,dataFrame_count,users)\n",
    "                    cnt+=1\n",
    "                    head+=1\n",
    "\n",
    "                else:\n",
    "                    cnt_trans+=add_user(tail,u_list,dataFrame_count,users)\n",
    "                    tail-=1\n",
    "                    cnt=0\n",
    "    #             print 'head',head\n",
    "    #             print 'tail',tail\n",
    "    #             print 'cnt_trans',cnt_trans\n",
    "                if head == tail+1:\n",
    "                        head = 0\n",
    "                        tail = len(u_list)-1\n",
    "                        cnt_trans = 0\n",
    "                        cnt = 0\n",
    "                        #if you have go through all users - return in order not to overfill epoch\n",
    "                        #the same logic could have been achieved with break and without the yield line\n",
    "                        print \"##########ALL COVERED##########\"\n",
    "                        # yield users\n",
    "                        # users = set()\n",
    "                        break\n",
    "                        \n",
    "    #                     print len(users)\n",
    "    #         print head\n",
    "    #         print tail\n",
    "            # print 'return list length:',len(users)\n",
    "    #         print '# users expiriencing both', len(u_list)-len(users)\n",
    "            total_sequences+=cnt_trans\n",
    "            yield users\n",
    "def eval_trans_generator(disk_engine,encoders,table='data_trim',batch_size=512,usr_ratio=80,class_weight=None,lbl_pad_val = 2, pad_val = -1):\n",
    "    user_gen = user_generator(disk_engine,usr_ratio=usr_ratio,batch_size=batch_size,table=table)\n",
    "    print \"Users generator\"\n",
    "    while True:\n",
    "        users = next(user_gen)\n",
    "        yield sequence_generator(users,encoders,disk_engine,lbl_pad_val,pad_val,mode='test',table=table,class_weight=class_weight)\n",
    "\n",
    "def eval_users_generator(disk_engine,encoders,table='data_trim',batch_size=512,usr_ratio=80,class_weight=None,lbl_pad_val = 2, pad_val = -1):\n",
    "    user_gen = user_generator(disk_engine,usr_ratio=usr_ratio,batch_size=batch_size,table=table,mode='test')\n",
    "    print \"Users generator\"\n",
    "    while True:\n",
    "        users = next(user_gen)\n",
    "        yield sequence_generator(users,encoders,disk_engine,lbl_pad_val,pad_val,mode='train',table=table,class_weight=class_weight)   \n",
    "\n",
    "\n",
    "def data_generator(user_mode,trans_mode,disk_engine,encoders,table,\n",
    "                   batch_size=512,usr_ratio=80,class_weight=None,lbl_pad_val = 2,\n",
    "                   pad_val = -1,cutt_off_date='2014-05-11',sub_sample=None,epoch_size=None):\n",
    "    user_gen = user_generator(disk_engine,usr_ratio=usr_ratio,batch_size=batch_size,table=table,mode=user_mode,trans_mode=trans_mode,sub_sample=sub_sample)\n",
    "    print \"Users generator\"\n",
    "    last_date = get_last_date(cutt_off_date,table,disk_engine)\n",
    "    print 'last_date calculated!'\n",
    "    x_acc = []\n",
    "    y_acc = []\n",
    "    sample_w = []\n",
    "    total_eg = 0\n",
    "    while True:\n",
    "        print 'new users'\n",
    "        users = next(user_gen)\n",
    "        outs = sequence_generator(users,encoders,disk_engine,lbl_pad_val,pad_val,last_date,mode=trans_mode,table=table,class_weight=class_weight)\n",
    "        \n",
    "        if not(epoch_size == None):\n",
    "            while True:\n",
    "                num_seq = outs[0].shape[0]\n",
    "                print 'num_Seq',num_seq\n",
    "               \n",
    "                remain = epoch_size - (total_eg + num_seq)\n",
    "                print '{remain} = {epoch_size} - ({total_eg}+{num_seq})'.format(remain=remain,epoch_size=epoch_size,total_eg=total_eg,num_seq=num_seq)   \n",
    "                print 'remain',remain\n",
    "                if remain >=0:\n",
    "                    total_eg +=num_seq\n",
    "                    yield outs\n",
    "                else:\n",
    "                    ### remain <0 => num_seq - remain\n",
    "                    cutline = num_seq + remain\n",
    "                    temp = []\n",
    "                    for i in range(len(outs)):\n",
    "                        temp.append(outs[i][0:cutline])\n",
    "                    yield tuple(temp)\n",
    "                    ####end of epoch!\n",
    "\n",
    "                    total_eg = 0\n",
    "                    temp = []\n",
    "                    for i in range(len(outs)):\n",
    "                        temp.append(outs[i][cutline:])\n",
    "                    outs =  tuple(temp) \n",
    "                if remain >=0:\n",
    "                    break\n",
    "        else:    \n",
    "            yield outs\n",
    "\n",
    "def eval_auc_generator(model, generator, val_samples, max_q_size=10000,plt_filename=None,acc=True):\n",
    "    '''Generates predictions for the input samples from a data generator.\n",
    "    The generator should return the same kind of data as accepted by\n",
    "    `predict_on_batch`.\n",
    "\n",
    "    # Arguments\n",
    "        generator: generator yielding batches of input samples.\n",
    "        val_samples: total number of samples to generate from `generator`\n",
    "            before returning.\n",
    "        max_q_size: maximum size for the generator queue\n",
    "\n",
    "    # Returns\n",
    "        Numpy array(s) of predictions.\n",
    "    '''\n",
    "\n",
    "\n",
    "    processed_samples = 0\n",
    "    wait_time = 0.01\n",
    "    all_outs = []\n",
    "    all_y_r = []\n",
    "    all_y_hat = []\n",
    "    data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)\n",
    "\n",
    "    while processed_samples < val_samples:\n",
    "        generator_output = None\n",
    "        while not _stop.is_set():\n",
    "            if not data_gen_queue.empty():\n",
    "                generator_output = data_gen_queue.get()\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "        if isinstance(generator_output, tuple):\n",
    "            if len(generator_output) == 2:\n",
    "                x, y = generator_output\n",
    "                sample_weight = None\n",
    "            elif len(generator_output) == 3:\n",
    "                x, y, sample_weight = generator_output\n",
    "            else:\n",
    "                _stop.set()\n",
    "                raise Exception('output of generator should be a tuple '\n",
    "                                '(x, y, sample_weight) '\n",
    "                                'or (x, y). Found: ' + str(generator_output))\n",
    "        else:\n",
    "            _stop.set()\n",
    "            raise Exception('output of generator should be a tuple '\n",
    "                                '(x, y, sample_weight) '\n",
    "                                'or (x, y). Found: ' + str(generator_output))\n",
    "\n",
    "        try:\n",
    "            if x.size != 0:\n",
    "                y_hat = model.predict_on_batch(x)\n",
    "                y_r = y.ravel()\n",
    "                y_hat_r = y_hat[:,:,1].ravel()\n",
    "                pad_ids = np.where(y_r!=2)\n",
    "                all_y_r.extend(y_r[pad_ids])\n",
    "                all_y_hat.extend(y_hat_r[pad_ids])\n",
    "        except:\n",
    "            _stop.set()\n",
    "            raise\n",
    "        nb_samples = x.shape[0]   \n",
    "\n",
    "        processed_samples += nb_samples\n",
    "\n",
    "    _stop.set()\n",
    "\n",
    "\n",
    "    all_y_r = np.array(all_y_r,dtype=np.dtype(float))\n",
    "    all_y_hat = np.array(all_y_hat,dtype=np.dtype(float))\n",
    "    print all_y_r.shape\n",
    "    print all_y_hat.shape\n",
    "    print '# fraud transactions',all_y_r[np.where(all_y_r==1)].shape\n",
    "    print '# total transactions', all_y_r.shape\n",
    "    print '# total sequences',processed_samples\n",
    "    #######ROC CURVE\n",
    "    fpr,tpr,tresholds = roc_curve(all_y_r,all_y_hat)\n",
    "    # print all_y_hat\n",
    "    # print tresholds\n",
    "    print 'False Positive Rates'\n",
    "    print fpr\n",
    "    print 'True Positive Rates'\n",
    "    print tpr\n",
    "    ####################DETERMINE CUTOFF TRESHOLD############\n",
    "    tr_shape = tresholds.shape\n",
    "    print 'Tresholds shape:',tr_shape\n",
    "    if tr_shape[0]>3:\n",
    "        cutt_off_tr = tresholds[3]\n",
    "    else:\n",
    "        cutt_off_tr = tresholds[-1]\n",
    "\n",
    "\n",
    "\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    print 'AUC:',auc_val\n",
    "    ############CLASSIFICATION REPORT########################\n",
    "    target_names = ['Genuine', 'Fraud']\n",
    "    #########Need to determine treshold \n",
    "    all_y_hat[np.where(all_y_hat>=cutt_off_tr)] = 1\n",
    "    all_y_hat[np.where(all_y_hat<cutt_off_tr)]  = 0\n",
    "    clc_report = classification_report(all_y_r, all_y_hat, target_names=target_names,digits=7)\n",
    "    ############Accuracy\n",
    "    acc = accuracy_score(all_y_r,all_y_hat)\n",
    "    if plt_filename != None and not np.isnan(auc_val):\n",
    "        trace = Scatter(x=fpr,y=tpr)\n",
    "        data = [trace]\n",
    "        title = 'ROC'\n",
    "        layout = Layout(title=title, width=800, height=640)\n",
    "        fig = Figure(data=data, layout=layout)\n",
    "        print plt_filename\n",
    "        py.image.save_as(fig,filename=plt_filename)\n",
    "    return [auc_val,clc_report,acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    \"postgresql+pg8000://script@localhost:5432/ccfd\",\n",
    "    isolation_level=\"AUTOCOMMIT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute('drop TABLE event;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
